  File "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/course_example_predicting_Non_dest_fruit_quality_monitoring.py", line 2950
    global NUM_EPOCHS, LEARNING_RATE, PATIENCE, SIMULATE_RESULTS, DATA_DIR
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: name 'NUM_EPOCHS' is used prior to global declaration
Using device: cuda
PyTorch version: 2.9.1+cu126
============================================================
CONFIGURATION
============================================================

Selected Preprocessing Configuration: prep_base
  Normalization: standard
  Window Strategy: Non-overlapping
  Drift Handling: Disabled

Other Parameters:
  Sequence Length: 100
  Batch Size: 32
  Hold-out Test Size: 25% (not used during training)
  Validation Size: 20% of training data

üí° Available Preprocessing Configurations:
  - prep_base: norm=standard, drift=False, window=None ‚Üê SELECTED
  - prep_no_norm: norm=none, drift=False, window=None
  - prep_with_drift: norm=standard, drift=True, window=None
  - prep_sliding_window: norm=standard, drift=False, window=1
  - prep_minmax: norm=minmax, drift=False, window=None
  - prep_robust: norm=robust, drift=False, window=None
============================================================
--- Loading data from ./AllSmaples-Report ---
Loaded 6540 sequences
Sequence shape: (100, 9)
Number of classes: 5
Class distribution: {0: 1520, 1: 1327, 2: 1284, 3: 1247, 4: 1162}
Normalization: none
Window stride: 100 (non-overlapping)
Drift handling: Disabled

Data Split:
  Training set: 3924 samples (60.0%)
  Validation set: 981 samples (15.0%)
  Hold-out test set: 1635 samples (25.0%)
StandardScaler fitted on training data

Data Preprocessing Verification:
  Train sequences shape: (3924, 100, 9)
  Train sequences mean: -0.0000, std: 1.0000
  Val sequences shape: (981, 100, 9)
  Val sequences mean: -0.0046, std: 0.9794
  Test sequences shape: (1635, 100, 9)
  Test sequences mean: 0.0320, std: 1.0278
  Train labels distribution: [912 796 770 748 698]
  Val labels distribution: [228 199 193 187 174]
  Test labels distribution: [380 332 321 312 290]

Dataset Info:
  Number of features (sensors): 9
  Number of classes: 5
  Sequence length: 100

Data Loaders Created:
  Training samples: 3924 (used for training)
  Validation samples: 981 (used for validation during training)
  Hold-out test samples: 1635 (reserved for final evaluation)
  Batch size: 32
============================================================
MULTIPLE CONFIGURATION TRAINING
============================================================

Defined 7 model configurations:

1. cnn1d_base
   Model Type: CNN1D
   Key Hyperparameters:
      activation: relu
      dropout_conv: 0.3
      dropout_fc: 0.5

2. cnn1d_deep
   Model Type: CNN1D
   Key Hyperparameters:
      activation: gelu
      dropout_conv: 0.4
      dropout_fc: 0.6

3. cnn1d_wide
   Model Type: CNN1D
   Key Hyperparameters:
      activation: swish
      dropout_conv: 0.2
      dropout_fc: 0.4

4. cnn_lstm_base
   Model Type: CNN_LSTM
   Key Hyperparameters:
      activation: relu
      lstm_hidden: 128
      lstm_layers: 2

5. cnn_lstm_large
   Model Type: CNN_LSTM
   Key Hyperparameters:
      activation: gelu
      lstm_hidden: 256
      lstm_layers: 3

6. cnn_transformer_base
   Model Type: CNN_Transformer
   Key Hyperparameters:
      activation: relu
      d_model: 128
      nhead: 8
      num_layers: 2

7. cnn_transformer_large
   Model Type: CNN_Transformer
   Key Hyperparameters:
      activation: gelu
      d_model: 256
      nhead: 16
      num_layers: 4

============================================================
üí° All configurations will be trained and saved for comparison in Streamlit
============================================================
============================================================
HYPERPARAMETER CONFIGURATION
============================================================

1D CNN Configuration:
  filters: [64, 128, 256]
  kernel_sizes: [5, 5, 3]
  fc_sizes: [128, 64]
  dropout_conv: 0.3
  dropout_fc: 0.5
  activation: relu
  use_batch_norm: True
  pool_size: 2

CNN + LSTM Configuration:
  cnn_filters: [64, 128]
  cnn_kernel_sizes: [5, 5]
  lstm_hidden: 128
  lstm_layers: 2
  lstm_bidirectional: True
  fc_sizes: [128, 64]
  dropout_conv: 0.3
  dropout_lstm: 0.3
  dropout_fc: 0.5
  activation: relu
  use_batch_norm: True
  pool_size: 2

CNN + Transformer Configuration:
  cnn_filters: [64, 128]
  cnn_kernel_sizes: [5, 5]
  d_model: 128
  nhead: 8
  num_layers: 2
  dim_feedforward: 512
  fc_sizes: [128, 64]
  dropout_conv: 0.3
  dropout_transformer: 0.1
  dropout_fc: 0.5
  activation: relu
  use_batch_norm: True
  pool_size: 2
============================================================

üí° TIP: Modify the *_CONFIG dictionaries above to experiment with different hyperparameters!
   - Try different activation functions: 'gelu', 'swish', 'elu'
   - Adjust filter sizes and kernel sizes for different feature extraction
   - Tune dropout rates to prevent overfitting
   - Experiment with FC layer sizes
============================================================
Saved scaler to saved_models_pytorch/preprocessing_scaler.pkl
============================================================
EXAMPLE: Loading Model and Making Predictions
============================================================

Loading model: saved_models_pytorch/prep_no_norm__cnn1d_deep.pth

Model loaded successfully!
  Preprocessing config: {'name': 'prep_no_norm', 'normalization': 'none', 'window_stride': None, 'handle_drift': False, 'drift_method': None, 'sequence_length': 100, 'num_features': 9}
  Scaler loaded: False

Sample Prediction (with proper preprocessing):
  True Label: D1
  Predicted Label: D1
  Probabilities:
    D1: 1.0000
    D2: 0.0000
    D3: 0.0000
    D4: 0.0000
    D5: 0.0000
============================================================
PREPROCESSING IMPACT ANALYSIS
============================================================
Current Configuration:
  Normalization: standard
  Window Strategy: Non-overlapping
  Drift Handling: Disabled

============================================================
PREPROCESSING OPTIONS EXPLANATION
============================================================

1. NORMALIZATION & SCALING:
   - 'none': Raw sensor values (no scaling)
   - 'standard': StandardScaler - normalizes to mean=0, std=1
   - 'minmax': MinMaxScaler - scales to range [0, 1]
   - 'robust': RobustScaler - uses median/IQR, robust to outliers
   - 'per_sensor': Independent scaling per sensor (handles different sensor scales)

2. WINDOWING & SEGMENTATION:
   - None (default): Non-overlapping windows (no data overlap)
   - stride=1: Sliding window (maximum data usage, more samples)
   - stride=N: Custom stride (balance between samples and overlap)

3. VOC DRIFT HANDLING:
   - 'baseline': Subtract initial value (removes baseline drift)
   - 'relative': Normalize by baseline (relative change from baseline)
   - 'moving_baseline': Use moving average as baseline (more robust)

============================================================
TO COMPARE PREPROCESSING IMPACT:
============================================================
1. Run notebook with current settings and save results
2. Change NORMALIZATION, WINDOW_STRIDE, or HANDLE_DRIFT
3. Run again and compare metrics
4. Key metrics to compare: Accuracy, F1-Score, training time
============================================================
============================================================
TRAINING ALL PREPROCESSING + MODEL CONFIGURATIONS
============================================================
Total preprocessing configs: 6
Total model configs: 7
Total combinations: 42
Training parameters: epochs=50, lr=0.001, patience=10
Simulate results: False
============================================================

------------------------------------------------------------
Preprocessing: prep_base
--- Loading data from ./AllSmaples-Report ---
Loaded 6540 sequences
Sequence shape: (100, 9)
Number of classes: 5
Class distribution: {0: 1520, 1: 1327, 2: 1284, 3: 1247, 4: 1162}
Normalization: none
Window stride: 100 (non-overlapping)
Drift handling: Disabled

Training: prep_base__cnn1d_base

============================================================
Training prep_base__cnn1d_base
============================================================
Epoch [1/50]
  Train Loss: 0.8697, Train Acc: 62.84%
  Val Loss: 0.3873, Val Acc: 86.03%
Epoch [5/50]
  Train Loss: 0.1399, Train Acc: 96.05%
  Val Loss: 0.1448, Val Acc: 96.43%
Epoch [10/50]
  Train Loss: 0.0766, Train Acc: 98.01%
  Val Loss: 0.0086, Val Acc: 99.80%
Epoch [15/50]
  Train Loss: 0.0465, Train Acc: 98.80%
  Val Loss: 0.0020, Val Acc: 99.90%

Early stopping at epoch 17
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_base__cnn1d_base/prep_base__cnn1d_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_base__cnn1d_base/prep_base__cnn1d_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_base__cnn1d_base/prep_base__cnn1d_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_base__cnn1d_base/prep_base__cnn1d_base_classification_report.txt
Saved: saved_models_pytorch/prep_base__cnn1d_base.pth

Training: prep_base__cnn1d_deep

============================================================
Training prep_base__cnn1d_deep
============================================================
Epoch [1/50]
  Train Loss: 1.0784, Train Acc: 50.82%
  Val Loss: 0.9884, Val Acc: 59.94%
Epoch [5/50]
  Train Loss: 0.2837, Train Acc: 91.56%
  Val Loss: 0.3318, Val Acc: 90.52%
Epoch [10/50]
  Train Loss: 0.1785, Train Acc: 95.80%
  Val Loss: 0.2032, Val Acc: 95.31%
Epoch [15/50]
  Train Loss: 0.0990, Train Acc: 97.78%
  Val Loss: 0.0843, Val Acc: 96.13%
Epoch [20/50]
  Train Loss: 0.0746, Train Acc: 98.42%
  Val Loss: 0.1353, Val Acc: 96.02%
Epoch [25/50]
  Train Loss: 0.0358, Train Acc: 99.08%
  Val Loss: 0.0433, Val Acc: 98.88%
Epoch [30/50]
  Train Loss: 0.0369, Train Acc: 98.96%
  Val Loss: 0.0095, Val Acc: 99.90%

Early stopping at epoch 31
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_base__cnn1d_deep/prep_base__cnn1d_deep_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_base__cnn1d_deep/prep_base__cnn1d_deep_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_base__cnn1d_deep/prep_base__cnn1d_deep_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_base__cnn1d_deep/prep_base__cnn1d_deep_classification_report.txt
Saved: saved_models_pytorch/prep_base__cnn1d_deep.pth

Training: prep_base__cnn1d_wide

============================================================
Training prep_base__cnn1d_wide
============================================================
Epoch [1/50]
  Train Loss: 0.4694, Train Acc: 81.75%
  Val Loss: 0.1216, Val Acc: 95.82%
Epoch [5/50]
  Train Loss: 0.0915, Train Acc: 97.38%
  Val Loss: 0.0374, Val Acc: 98.88%
Epoch [10/50]
  Train Loss: 0.1006, Train Acc: 97.68%
  Val Loss: 0.0079, Val Acc: 99.90%
Epoch [15/50]
  Train Loss: 0.0475, Train Acc: 98.73%
  Val Loss: 0.0407, Val Acc: 98.98%

Early stopping at epoch 17
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_base__cnn1d_wide/prep_base__cnn1d_wide_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_base__cnn1d_wide/prep_base__cnn1d_wide_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_base__cnn1d_wide/prep_base__cnn1d_wide_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_base__cnn1d_wide/prep_base__cnn1d_wide_classification_report.txt
Saved: saved_models_pytorch/prep_base__cnn1d_wide.pth

Training: prep_base__cnn_lstm_base

============================================================
Training prep_base__cnn_lstm_base
============================================================
Epoch [1/50]
  Train Loss: 0.9765, Train Acc: 54.82%
  Val Loss: 0.5722, Val Acc: 61.57%
Epoch [5/50]
  Train Loss: 0.1751, Train Acc: 95.36%
  Val Loss: 0.0336, Val Acc: 98.98%
Epoch [10/50]
  Train Loss: 0.1184, Train Acc: 97.15%
  Val Loss: 0.2168, Val Acc: 95.31%
Epoch [15/50]
  Train Loss: 0.0880, Train Acc: 97.60%
  Val Loss: 0.0117, Val Acc: 99.18%
Epoch [20/50]
  Train Loss: 0.0851, Train Acc: 97.60%
  Val Loss: 0.0068, Val Acc: 99.80%
Epoch [25/50]
  Train Loss: 0.0308, Train Acc: 99.24%
  Val Loss: 0.0146, Val Acc: 99.69%
Epoch [30/50]
  Train Loss: 0.0204, Train Acc: 99.41%
  Val Loss: 0.0204, Val Acc: 99.80%
Epoch [35/50]
  Train Loss: 0.0098, Train Acc: 99.72%
  Val Loss: 0.0026, Val Acc: 99.90%

Early stopping at epoch 36
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_base__cnn_lstm_base/prep_base__cnn_lstm_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_base__cnn_lstm_base/prep_base__cnn_lstm_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_base__cnn_lstm_base/prep_base__cnn_lstm_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_base__cnn_lstm_base/prep_base__cnn_lstm_base_classification_report.txt
Saved: saved_models_pytorch/prep_base__cnn_lstm_base.pth

Training: prep_base__cnn_lstm_large

============================================================
Training prep_base__cnn_lstm_large
============================================================
Epoch [1/50]
  Train Loss: 0.9432, Train Acc: 53.62%
  Val Loss: 0.6329, Val Acc: 62.59%
Epoch [5/50]
  Train Loss: 0.2717, Train Acc: 91.51%
  Val Loss: 0.1565, Val Acc: 93.78%
Epoch [10/50]
  Train Loss: 0.1127, Train Acc: 96.71%
  Val Loss: 0.3589, Val Acc: 91.85%
Epoch [15/50]
  Train Loss: 0.0799, Train Acc: 97.76%
  Val Loss: 0.0350, Val Acc: 99.18%
Epoch [20/50]
  Train Loss: 0.1313, Train Acc: 96.89%
  Val Loss: 0.2736, Val Acc: 92.46%
Epoch [25/50]
  Train Loss: 0.0566, Train Acc: 98.47%
  Val Loss: 0.0217, Val Acc: 99.29%

Early stopping at epoch 28
Best validation accuracy: 99.39%

Training completed. Best validation accuracy: 99.39%
Saved training curves: saved_models_pytorch/reports/prep_base__cnn_lstm_large/prep_base__cnn_lstm_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_base__cnn_lstm_large/prep_base__cnn_lstm_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_base__cnn_lstm_large/prep_base__cnn_lstm_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_base__cnn_lstm_large/prep_base__cnn_lstm_large_classification_report.txt
Saved: saved_models_pytorch/prep_base__cnn_lstm_large.pth

Training: prep_base__cnn_transformer_base

============================================================
Training prep_base__cnn_transformer_base
============================================================
Epoch [1/50]
  Train Loss: 0.9117, Train Acc: 59.12%
  Val Loss: 0.5018, Val Acc: 76.45%
Epoch [5/50]
  Train Loss: 0.1637, Train Acc: 95.62%
  Val Loss: 0.1922, Val Acc: 94.50%
Epoch [10/50]
  Train Loss: 0.0779, Train Acc: 98.39%
  Val Loss: 0.0058, Val Acc: 99.90%
Epoch [15/50]
  Train Loss: 0.0712, Train Acc: 98.19%
  Val Loss: 0.0645, Val Acc: 96.94%
Epoch [20/50]
  Train Loss: 0.0208, Train Acc: 99.72%
  Val Loss: 0.0066, Val Acc: 99.90%
Epoch [25/50]
  Train Loss: 0.0489, Train Acc: 98.85%
  Val Loss: 0.0169, Val Acc: 99.18%

Early stopping at epoch 28
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_base__cnn_transformer_base/prep_base__cnn_transformer_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_base__cnn_transformer_base/prep_base__cnn_transformer_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_base__cnn_transformer_base/prep_base__cnn_transformer_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_base__cnn_transformer_base/prep_base__cnn_transformer_base_classification_report.txt
Saved: saved_models_pytorch/prep_base__cnn_transformer_base.pth

Training: prep_base__cnn_transformer_large

============================================================
Training prep_base__cnn_transformer_large
============================================================
Epoch [1/50]
  Train Loss: 1.0092, Train Acc: 54.28%
  Val Loss: 0.6847, Val Acc: 62.28%
Epoch [5/50]
  Train Loss: 1.2593, Train Acc: 35.65%
  Val Loss: 1.2308, Val Acc: 36.90%
Epoch [10/50]
  Train Loss: 1.2894, Train Acc: 40.16%
  Val Loss: 1.3965, Val Acc: 35.37%

Early stopping at epoch 11
Best validation accuracy: 62.28%

Training completed. Best validation accuracy: 62.28%
Saved training curves: saved_models_pytorch/reports/prep_base__cnn_transformer_large/prep_base__cnn_transformer_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_base__cnn_transformer_large/prep_base__cnn_transformer_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_base__cnn_transformer_large/prep_base__cnn_transformer_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_base__cnn_transformer_large/prep_base__cnn_transformer_large_classification_report.txt
Saved: saved_models_pytorch/prep_base__cnn_transformer_large.pth

------------------------------------------------------------
Preprocessing: prep_no_norm
--- Loading data from ./AllSmaples-Report ---
Loaded 6540 sequences
Sequence shape: (100, 9)
Number of classes: 5
Class distribution: {0: 1520, 1: 1327, 2: 1284, 3: 1247, 4: 1162}
Normalization: none
Window stride: 100 (non-overlapping)
Drift handling: Disabled

Training: prep_no_norm__cnn1d_base

============================================================
Training prep_no_norm__cnn1d_base
============================================================
Epoch [1/50]
  Train Loss: 0.8209, Train Acc: 64.35%
  Val Loss: 0.7607, Val Acc: 75.64%
Epoch [5/50]
  Train Loss: 0.1987, Train Acc: 94.42%
  Val Loss: 0.1104, Val Acc: 96.02%
Epoch [10/50]
  Train Loss: 0.1359, Train Acc: 96.33%
  Val Loss: 0.0788, Val Acc: 96.53%
Epoch [15/50]
  Train Loss: 0.0933, Train Acc: 97.50%
  Val Loss: 0.0047, Val Acc: 99.80%
Epoch [20/50]
  Train Loss: 0.0677, Train Acc: 98.45%
  Val Loss: 0.1041, Val Acc: 96.94%
Epoch [25/50]
  Train Loss: 0.0564, Train Acc: 98.73%
  Val Loss: 0.0286, Val Acc: 99.49%
Epoch [30/50]
  Train Loss: 0.0178, Train Acc: 99.52%
  Val Loss: 0.0008, Val Acc: 100.00%

Early stopping at epoch 34
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_no_norm__cnn1d_base/prep_no_norm__cnn1d_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn1d_base/prep_no_norm__cnn1d_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn1d_base/prep_no_norm__cnn1d_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_no_norm__cnn1d_base/prep_no_norm__cnn1d_base_classification_report.txt
Saved: saved_models_pytorch/prep_no_norm__cnn1d_base.pth

Training: prep_no_norm__cnn1d_deep

============================================================
Training prep_no_norm__cnn1d_deep
============================================================
Epoch [1/50]
  Train Loss: 1.2248, Train Acc: 45.46%
  Val Loss: 1.5572, Val Acc: 40.67%
Epoch [5/50]
  Train Loss: 0.4727, Train Acc: 77.12%
  Val Loss: 0.5744, Val Acc: 70.85%
Epoch [10/50]
  Train Loss: 0.3112, Train Acc: 90.39%
  Val Loss: 0.1214, Val Acc: 96.43%
Epoch [15/50]
  Train Loss: 0.1834, Train Acc: 95.74%
  Val Loss: 0.0396, Val Acc: 99.59%
Epoch [20/50]
  Train Loss: 0.1188, Train Acc: 97.27%
  Val Loss: 0.2421, Val Acc: 97.25%
Epoch [25/50]
  Train Loss: 0.0811, Train Acc: 97.94%
  Val Loss: 0.2225, Val Acc: 94.90%

Early stopping at epoch 25
Best validation accuracy: 99.59%

Training completed. Best validation accuracy: 99.59%
Saved training curves: saved_models_pytorch/reports/prep_no_norm__cnn1d_deep/prep_no_norm__cnn1d_deep_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn1d_deep/prep_no_norm__cnn1d_deep_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn1d_deep/prep_no_norm__cnn1d_deep_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_no_norm__cnn1d_deep/prep_no_norm__cnn1d_deep_classification_report.txt
Saved: saved_models_pytorch/prep_no_norm__cnn1d_deep.pth

Training: prep_no_norm__cnn1d_wide

============================================================
Training prep_no_norm__cnn1d_wide
============================================================
Epoch [1/50]
  Train Loss: 0.6031, Train Acc: 76.89%
  Val Loss: 0.3539, Val Acc: 85.32%
Epoch [5/50]
  Train Loss: 0.1558, Train Acc: 95.23%
  Val Loss: 0.1150, Val Acc: 95.41%
Epoch [10/50]
  Train Loss: 0.0900, Train Acc: 97.02%
  Val Loss: 0.8351, Val Acc: 85.12%
Epoch [15/50]
  Train Loss: 0.0507, Train Acc: 98.60%
  Val Loss: 0.0049, Val Acc: 99.90%
Epoch [20/50]
  Train Loss: 0.0713, Train Acc: 98.24%
  Val Loss: 0.2974, Val Acc: 90.32%
Epoch [25/50]
  Train Loss: 0.0307, Train Acc: 99.29%
  Val Loss: 0.0047, Val Acc: 99.90%

Early stopping at epoch 25
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_no_norm__cnn1d_wide/prep_no_norm__cnn1d_wide_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn1d_wide/prep_no_norm__cnn1d_wide_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn1d_wide/prep_no_norm__cnn1d_wide_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_no_norm__cnn1d_wide/prep_no_norm__cnn1d_wide_classification_report.txt
Saved: saved_models_pytorch/prep_no_norm__cnn1d_wide.pth

Training: prep_no_norm__cnn_lstm_base

============================================================
Training prep_no_norm__cnn_lstm_base
============================================================
Epoch [1/50]
  Train Loss: 1.0440, Train Acc: 52.96%
  Val Loss: 0.6618, Val Acc: 67.79%
Epoch [5/50]
  Train Loss: 0.3206, Train Acc: 88.30%
  Val Loss: 1.0272, Val Acc: 76.76%
Epoch [10/50]
  Train Loss: 0.2121, Train Acc: 94.39%
  Val Loss: 0.1580, Val Acc: 94.29%
Epoch [15/50]
  Train Loss: 0.1525, Train Acc: 95.49%
  Val Loss: 0.1509, Val Acc: 93.88%
Epoch [20/50]
  Train Loss: 0.0629, Train Acc: 98.19%
  Val Loss: 0.0131, Val Acc: 99.39%
Epoch [25/50]
  Train Loss: 0.0423, Train Acc: 98.78%
  Val Loss: 0.2054, Val Acc: 97.76%
Epoch [30/50]
  Train Loss: 0.0266, Train Acc: 99.34%
  Val Loss: 0.0004, Val Acc: 100.00%

Early stopping at epoch 33
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_no_norm__cnn_lstm_base/prep_no_norm__cnn_lstm_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn_lstm_base/prep_no_norm__cnn_lstm_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn_lstm_base/prep_no_norm__cnn_lstm_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_no_norm__cnn_lstm_base/prep_no_norm__cnn_lstm_base_classification_report.txt
Saved: saved_models_pytorch/prep_no_norm__cnn_lstm_base.pth

Training: prep_no_norm__cnn_lstm_large

============================================================
Training prep_no_norm__cnn_lstm_large
============================================================
Epoch [1/50]
  Train Loss: 0.9258, Train Acc: 54.79%
  Val Loss: 0.7745, Val Acc: 58.51%
Epoch [5/50]
  Train Loss: 0.4351, Train Acc: 80.91%
  Val Loss: 0.3918, Val Acc: 80.33%
Epoch [10/50]
  Train Loss: 0.2152, Train Acc: 94.47%
  Val Loss: 0.3672, Val Acc: 91.13%
Epoch [15/50]
  Train Loss: 0.1042, Train Acc: 97.27%
  Val Loss: 0.0686, Val Acc: 98.27%
Epoch [20/50]
  Train Loss: 0.0806, Train Acc: 97.63%
  Val Loss: 0.2207, Val Acc: 95.62%
Epoch [25/50]
  Train Loss: 0.0883, Train Acc: 97.68%
  Val Loss: 0.4137, Val Acc: 89.60%
Epoch [30/50]
  Train Loss: 0.0610, Train Acc: 98.27%
  Val Loss: 0.0357, Val Acc: 99.29%

Early stopping at epoch 33
Best validation accuracy: 99.80%

Training completed. Best validation accuracy: 99.80%
Saved training curves: saved_models_pytorch/reports/prep_no_norm__cnn_lstm_large/prep_no_norm__cnn_lstm_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn_lstm_large/prep_no_norm__cnn_lstm_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn_lstm_large/prep_no_norm__cnn_lstm_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_no_norm__cnn_lstm_large/prep_no_norm__cnn_lstm_large_classification_report.txt
Saved: saved_models_pytorch/prep_no_norm__cnn_lstm_large.pth

Training: prep_no_norm__cnn_transformer_base

============================================================
Training prep_no_norm__cnn_transformer_base
============================================================
Epoch [1/50]
  Train Loss: 1.0270, Train Acc: 54.89%
  Val Loss: 1.1070, Val Acc: 52.09%
Epoch [5/50]
  Train Loss: 0.3275, Train Acc: 87.97%
  Val Loss: 0.5153, Val Acc: 79.20%
Epoch [10/50]
  Train Loss: 0.1327, Train Acc: 96.41%
  Val Loss: 1.1133, Val Acc: 80.12%
Epoch [15/50]
  Train Loss: 0.1151, Train Acc: 96.51%
  Val Loss: 0.0353, Val Acc: 98.57%
Epoch [20/50]
  Train Loss: 0.0972, Train Acc: 97.53%
  Val Loss: 0.0745, Val Acc: 96.94%
Epoch [25/50]
  Train Loss: 0.1074, Train Acc: 97.53%
  Val Loss: 0.0581, Val Acc: 97.86%
Epoch [30/50]
  Train Loss: 0.1694, Train Acc: 96.48%
  Val Loss: 0.1810, Val Acc: 94.60%
Epoch [35/50]
  Train Loss: 0.0233, Train Acc: 99.59%
  Val Loss: 0.0147, Val Acc: 99.69%
Epoch [40/50]
  Train Loss: 0.0144, Train Acc: 99.57%
  Val Loss: 0.0001, Val Acc: 100.00%

Early stopping at epoch 42
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_no_norm__cnn_transformer_base/prep_no_norm__cnn_transformer_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn_transformer_base/prep_no_norm__cnn_transformer_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn_transformer_base/prep_no_norm__cnn_transformer_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_no_norm__cnn_transformer_base/prep_no_norm__cnn_transformer_base_classification_report.txt
Saved: saved_models_pytorch/prep_no_norm__cnn_transformer_base.pth

Training: prep_no_norm__cnn_transformer_large

============================================================
Training prep_no_norm__cnn_transformer_large
============================================================
Epoch [1/50]
  Train Loss: 1.3735, Train Acc: 39.22%
  Val Loss: 1.2525, Val Acc: 42.71%
Epoch [5/50]
  Train Loss: 1.6076, Train Acc: 23.19%
  Val Loss: 1.6126, Val Acc: 19.67%
Epoch [10/50]
  Train Loss: 1.6062, Train Acc: 23.17%
  Val Loss: 1.6060, Val Acc: 23.24%

Early stopping at epoch 11
Best validation accuracy: 42.71%

Training completed. Best validation accuracy: 42.71%
Saved training curves: saved_models_pytorch/reports/prep_no_norm__cnn_transformer_large/prep_no_norm__cnn_transformer_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn_transformer_large/prep_no_norm__cnn_transformer_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_no_norm__cnn_transformer_large/prep_no_norm__cnn_transformer_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_no_norm__cnn_transformer_large/prep_no_norm__cnn_transformer_large_classification_report.txt
Saved: saved_models_pytorch/prep_no_norm__cnn_transformer_large.pth

------------------------------------------------------------
Preprocessing: prep_with_drift
--- Loading data from ./AllSmaples-Report ---
Loaded 6540 sequences
Sequence shape: (100, 9)
Number of classes: 5
Class distribution: {0: 1520, 1: 1327, 2: 1284, 3: 1247, 4: 1162}
Normalization: none
Window stride: 100 (non-overlapping)
Drift handling: Disabled

Training: prep_with_drift__cnn1d_base

============================================================
Training prep_with_drift__cnn1d_base
============================================================
Epoch [1/50]
  Train Loss: 1.6308, Train Acc: 22.53%
  Val Loss: 1.5916, Val Acc: 26.71%
Epoch [5/50]
  Train Loss: 1.4263, Train Acc: 34.96%
  Val Loss: 1.2878, Val Acc: 40.27%
Epoch [10/50]
  Train Loss: 1.2183, Train Acc: 43.86%
  Val Loss: 1.1838, Val Acc: 44.44%
Epoch [15/50]
  Train Loss: 1.1573, Train Acc: 47.83%
  Val Loss: 1.0740, Val Acc: 52.70%
Epoch [20/50]
  Train Loss: 1.0583, Train Acc: 52.80%
  Val Loss: 0.9771, Val Acc: 56.27%
Epoch [25/50]
  Train Loss: 0.9883, Train Acc: 56.07%
  Val Loss: 0.9301, Val Acc: 60.65%
Epoch [30/50]
  Train Loss: 0.9342, Train Acc: 58.36%
  Val Loss: 0.9175, Val Acc: 60.86%
Epoch [35/50]
  Train Loss: 0.8682, Train Acc: 63.79%
  Val Loss: 0.7697, Val Acc: 70.54%
Epoch [40/50]
  Train Loss: 0.8064, Train Acc: 68.99%
  Val Loss: 0.7157, Val Acc: 72.07%
Epoch [45/50]
  Train Loss: 0.7561, Train Acc: 71.08%
  Val Loss: 0.6412, Val Acc: 76.55%
Epoch [50/50]
  Train Loss: 0.6781, Train Acc: 73.37%
  Val Loss: 0.6614, Val Acc: 73.19%

Training completed. Best validation accuracy: 76.55%
Saved training curves: saved_models_pytorch/reports/prep_with_drift__cnn1d_base/prep_with_drift__cnn1d_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn1d_base/prep_with_drift__cnn1d_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn1d_base/prep_with_drift__cnn1d_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_with_drift__cnn1d_base/prep_with_drift__cnn1d_base_classification_report.txt
Saved: saved_models_pytorch/prep_with_drift__cnn1d_base.pth

Training: prep_with_drift__cnn1d_deep

============================================================
Training prep_with_drift__cnn1d_deep
============================================================
Epoch [1/50]
  Train Loss: 1.6091, Train Acc: 22.76%
  Val Loss: 1.5883, Val Acc: 25.48%
Epoch [5/50]
  Train Loss: 1.3465, Train Acc: 42.97%
  Val Loss: 1.4137, Val Acc: 33.03%
Epoch [10/50]
  Train Loss: 1.1439, Train Acc: 51.63%
  Val Loss: 1.1107, Val Acc: 54.94%
Epoch [15/50]
  Train Loss: 1.0457, Train Acc: 55.43%
  Val Loss: 1.0260, Val Acc: 55.86%
Epoch [20/50]
  Train Loss: 0.9739, Train Acc: 58.31%
  Val Loss: 0.9810, Val Acc: 59.53%
Epoch [25/50]
  Train Loss: 0.9495, Train Acc: 60.04%
  Val Loss: 0.8956, Val Acc: 63.40%
Epoch [30/50]
  Train Loss: 0.9075, Train Acc: 63.15%
  Val Loss: 0.8722, Val Acc: 64.83%
Epoch [35/50]
  Train Loss: 0.8969, Train Acc: 64.50%
  Val Loss: 0.7879, Val Acc: 71.25%
Epoch [40/50]
  Train Loss: 0.8166, Train Acc: 68.78%
  Val Loss: 0.7228, Val Acc: 74.31%
Epoch [45/50]
  Train Loss: 0.7275, Train Acc: 72.43%
  Val Loss: 0.6441, Val Acc: 77.06%
Epoch [50/50]
  Train Loss: 0.7454, Train Acc: 72.55%
  Val Loss: 0.6446, Val Acc: 76.66%

Training completed. Best validation accuracy: 77.78%
Saved training curves: saved_models_pytorch/reports/prep_with_drift__cnn1d_deep/prep_with_drift__cnn1d_deep_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn1d_deep/prep_with_drift__cnn1d_deep_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn1d_deep/prep_with_drift__cnn1d_deep_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_with_drift__cnn1d_deep/prep_with_drift__cnn1d_deep_classification_report.txt
Saved: saved_models_pytorch/prep_with_drift__cnn1d_deep.pth

Training: prep_with_drift__cnn1d_wide

============================================================
Training prep_with_drift__cnn1d_wide
============================================================
Epoch [1/50]
  Train Loss: 1.5300, Train Acc: 31.17%
  Val Loss: 1.2827, Val Acc: 42.41%
Epoch [5/50]
  Train Loss: 0.8916, Train Acc: 64.45%
  Val Loss: 0.8026, Val Acc: 68.60%
Epoch [10/50]
  Train Loss: 0.6936, Train Acc: 73.11%
  Val Loss: 0.6934, Val Acc: 74.01%
Epoch [15/50]
  Train Loss: 0.5339, Train Acc: 80.05%
  Val Loss: 0.6146, Val Acc: 76.04%
Epoch [20/50]
  Train Loss: 0.4372, Train Acc: 83.38%
  Val Loss: 0.6626, Val Acc: 75.64%
Epoch [25/50]
  Train Loss: 0.3838, Train Acc: 86.09%
  Val Loss: 0.6746, Val Acc: 76.86%
Epoch [30/50]
  Train Loss: 0.2177, Train Acc: 91.92%
  Val Loss: 0.7347, Val Acc: 77.17%
Epoch [35/50]
  Train Loss: 0.1212, Train Acc: 95.92%
  Val Loss: 0.7580, Val Acc: 79.00%
Epoch [40/50]
  Train Loss: 0.1065, Train Acc: 96.59%
  Val Loss: 0.7574, Val Acc: 79.31%
Epoch [45/50]
  Train Loss: 0.0902, Train Acc: 96.84%
  Val Loss: 0.8245, Val Acc: 78.29%
Epoch [50/50]
  Train Loss: 0.0764, Train Acc: 97.53%
  Val Loss: 0.8600, Val Acc: 79.00%

Training completed. Best validation accuracy: 79.71%
Saved training curves: saved_models_pytorch/reports/prep_with_drift__cnn1d_wide/prep_with_drift__cnn1d_wide_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn1d_wide/prep_with_drift__cnn1d_wide_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn1d_wide/prep_with_drift__cnn1d_wide_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_with_drift__cnn1d_wide/prep_with_drift__cnn1d_wide_classification_report.txt
Saved: saved_models_pytorch/prep_with_drift__cnn1d_wide.pth

Training: prep_with_drift__cnn_lstm_base

============================================================
Training prep_with_drift__cnn_lstm_base
============================================================
Epoch [1/50]
  Train Loss: 1.5998, Train Acc: 24.67%
  Val Loss: 1.5742, Val Acc: 27.73%
Epoch [5/50]
  Train Loss: 1.1841, Train Acc: 48.78%
  Val Loss: 1.0303, Val Acc: 55.25%
Epoch [10/50]
  Train Loss: 0.8463, Train Acc: 67.15%
  Val Loss: 0.8130, Val Acc: 68.91%
Epoch [15/50]
  Train Loss: 0.7050, Train Acc: 73.06%
  Val Loss: 0.6795, Val Acc: 74.21%
Epoch [20/50]
  Train Loss: 0.6091, Train Acc: 76.86%
  Val Loss: 0.6095, Val Acc: 76.15%
Epoch [25/50]
  Train Loss: 0.5529, Train Acc: 79.10%
  Val Loss: 0.5407, Val Acc: 78.80%
Epoch [30/50]
  Train Loss: 0.5218, Train Acc: 80.22%
  Val Loss: 0.5816, Val Acc: 78.90%
Epoch [35/50]
  Train Loss: 0.4279, Train Acc: 83.72%
  Val Loss: 0.5592, Val Acc: 80.12%
Epoch [40/50]
  Train Loss: 0.4121, Train Acc: 83.94%
  Val Loss: 0.5012, Val Acc: 80.53%
Epoch [45/50]
  Train Loss: 0.3618, Train Acc: 86.21%
  Val Loss: 0.5676, Val Acc: 80.53%

Early stopping at epoch 47
Best validation accuracy: 81.55%

Training completed. Best validation accuracy: 81.55%
Saved training curves: saved_models_pytorch/reports/prep_with_drift__cnn_lstm_base/prep_with_drift__cnn_lstm_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn_lstm_base/prep_with_drift__cnn_lstm_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn_lstm_base/prep_with_drift__cnn_lstm_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_with_drift__cnn_lstm_base/prep_with_drift__cnn_lstm_base_classification_report.txt
Saved: saved_models_pytorch/prep_with_drift__cnn_lstm_base.pth

Training: prep_with_drift__cnn_lstm_large

============================================================
Training prep_with_drift__cnn_lstm_large
============================================================
Epoch [1/50]
  Train Loss: 1.5725, Train Acc: 27.27%
  Val Loss: 1.4949, Val Acc: 31.50%
Epoch [5/50]
  Train Loss: 1.0668, Train Acc: 55.78%
  Val Loss: 0.9367, Val Acc: 63.81%
Epoch [10/50]
  Train Loss: 0.7141, Train Acc: 72.22%
  Val Loss: 0.6220, Val Acc: 77.47%
Epoch [15/50]
  Train Loss: 0.6210, Train Acc: 76.55%
  Val Loss: 0.6631, Val Acc: 75.64%
Epoch [20/50]
  Train Loss: 0.5294, Train Acc: 79.87%
  Val Loss: 0.5490, Val Acc: 79.61%
Epoch [25/50]
  Train Loss: 0.5183, Train Acc: 80.53%
  Val Loss: 0.6131, Val Acc: 77.27%
Epoch [30/50]
  Train Loss: 0.4553, Train Acc: 83.15%
  Val Loss: 0.5264, Val Acc: 80.22%
Epoch [35/50]
  Train Loss: 0.4000, Train Acc: 85.81%
  Val Loss: 0.5452, Val Acc: 81.65%
Epoch [40/50]
  Train Loss: 0.3957, Train Acc: 85.65%
  Val Loss: 0.5822, Val Acc: 77.68%
Epoch [45/50]
  Train Loss: 0.2864, Train Acc: 89.12%
  Val Loss: 0.5836, Val Acc: 81.14%

Early stopping at epoch 45
Best validation accuracy: 81.65%

Training completed. Best validation accuracy: 81.65%
Saved training curves: saved_models_pytorch/reports/prep_with_drift__cnn_lstm_large/prep_with_drift__cnn_lstm_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn_lstm_large/prep_with_drift__cnn_lstm_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn_lstm_large/prep_with_drift__cnn_lstm_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_with_drift__cnn_lstm_large/prep_with_drift__cnn_lstm_large_classification_report.txt
Saved: saved_models_pytorch/prep_with_drift__cnn_lstm_large.pth

Training: prep_with_drift__cnn_transformer_base

============================================================
Training prep_with_drift__cnn_transformer_base
============================================================
Epoch [1/50]
  Train Loss: 1.6134, Train Acc: 21.87%
  Val Loss: 1.5697, Val Acc: 29.15%
Epoch [5/50]
  Train Loss: 1.3131, Train Acc: 44.65%
  Val Loss: 1.2255, Val Acc: 44.34%
Epoch [10/50]
  Train Loss: 1.1786, Train Acc: 46.92%
  Val Loss: 1.1517, Val Acc: 46.59%
Epoch [15/50]
  Train Loss: 1.1402, Train Acc: 48.29%
  Val Loss: 1.0980, Val Acc: 50.15%
Epoch [20/50]
  Train Loss: 1.0418, Train Acc: 54.74%
  Val Loss: 1.0345, Val Acc: 52.60%
Epoch [25/50]
  Train Loss: 0.9842, Train Acc: 58.54%
  Val Loss: 0.9730, Val Acc: 58.51%
Epoch [30/50]
  Train Loss: 0.9424, Train Acc: 59.81%
  Val Loss: 0.9104, Val Acc: 61.47%
Epoch [35/50]
  Train Loss: 0.9224, Train Acc: 61.47%
  Val Loss: 0.8727, Val Acc: 62.28%
Epoch [40/50]
  Train Loss: 0.8716, Train Acc: 65.09%
  Val Loss: 0.8921, Val Acc: 65.34%
Epoch [45/50]
  Train Loss: 0.8376, Train Acc: 66.82%
  Val Loss: 0.8224, Val Acc: 68.91%
Epoch [50/50]
  Train Loss: 0.7728, Train Acc: 69.52%
  Val Loss: 0.8058, Val Acc: 69.32%

Training completed. Best validation accuracy: 70.64%
Saved training curves: saved_models_pytorch/reports/prep_with_drift__cnn_transformer_base/prep_with_drift__cnn_transformer_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn_transformer_base/prep_with_drift__cnn_transformer_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn_transformer_base/prep_with_drift__cnn_transformer_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_with_drift__cnn_transformer_base/prep_with_drift__cnn_transformer_base_classification_report.txt
Saved: saved_models_pytorch/prep_with_drift__cnn_transformer_base.pth

Training: prep_with_drift__cnn_transformer_large

============================================================
Training prep_with_drift__cnn_transformer_large
============================================================
Epoch [1/50]
  Train Loss: 1.6193, Train Acc: 21.38%
  Val Loss: 1.6114, Val Acc: 20.29%
Epoch [5/50]
  Train Loss: 1.6091, Train Acc: 22.91%
  Val Loss: 1.6063, Val Acc: 23.24%
Epoch [10/50]
  Train Loss: 1.6060, Train Acc: 23.09%
  Val Loss: 1.6062, Val Acc: 23.24%

Early stopping at epoch 12
Best validation accuracy: 23.24%

Training completed. Best validation accuracy: 23.24%
Saved training curves: saved_models_pytorch/reports/prep_with_drift__cnn_transformer_large/prep_with_drift__cnn_transformer_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn_transformer_large/prep_with_drift__cnn_transformer_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_with_drift__cnn_transformer_large/prep_with_drift__cnn_transformer_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_with_drift__cnn_transformer_large/prep_with_drift__cnn_transformer_large_classification_report.txt
Saved: saved_models_pytorch/prep_with_drift__cnn_transformer_large.pth

------------------------------------------------------------
Preprocessing: prep_sliding_window
--- Loading data from ./AllSmaples-Report ---
Loaded 651681 sequences
Sequence shape: (100, 9)
Number of classes: 5
Class distribution: {0: 151401, 1: 132167, 2: 127968, 3: 124320, 4: 115825}
Normalization: none
Window stride: 1 (sliding)
Drift handling: Disabled

Training: prep_sliding_window__cnn1d_base

============================================================
Training prep_sliding_window__cnn1d_base
============================================================
Epoch [1/50]
  Train Loss: 0.0617, Train Acc: 98.35%
  Val Loss: 0.0003, Val Acc: 100.00%
Epoch [5/50]
  Train Loss: 0.0099, Train Acc: 99.80%
  Val Loss: 0.0006, Val Acc: 99.98%
Epoch [10/50]
  Train Loss: 0.0082, Train Acc: 99.87%
  Val Loss: 0.0028, Val Acc: 99.93%

Early stopping at epoch 11
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_sliding_window__cnn1d_base/prep_sliding_window__cnn1d_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn1d_base/prep_sliding_window__cnn1d_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn1d_base/prep_sliding_window__cnn1d_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_sliding_window__cnn1d_base/prep_sliding_window__cnn1d_base_classification_report.txt
Saved: saved_models_pytorch/prep_sliding_window__cnn1d_base.pth

Training: prep_sliding_window__cnn1d_deep

============================================================
Training prep_sliding_window__cnn1d_deep
============================================================
Epoch [1/50]
  Train Loss: 0.1147, Train Acc: 97.08%
  Val Loss: 0.0389, Val Acc: 98.88%
Epoch [5/50]
  Train Loss: 0.0265, Train Acc: 99.56%
  Val Loss: 0.0210, Val Acc: 99.68%
Epoch [10/50]
  Train Loss: 0.0196, Train Acc: 99.69%
  Val Loss: 0.0705, Val Acc: 97.19%
Epoch [15/50]
  Train Loss: 0.0176, Train Acc: 99.74%
  Val Loss: 0.0013, Val Acc: 99.99%

Early stopping at epoch 19
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_sliding_window__cnn1d_deep/prep_sliding_window__cnn1d_deep_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn1d_deep/prep_sliding_window__cnn1d_deep_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn1d_deep/prep_sliding_window__cnn1d_deep_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_sliding_window__cnn1d_deep/prep_sliding_window__cnn1d_deep_classification_report.txt
Saved: saved_models_pytorch/prep_sliding_window__cnn1d_deep.pth

Training: prep_sliding_window__cnn1d_wide

============================================================
Training prep_sliding_window__cnn1d_wide
============================================================
Epoch [1/50]
  Train Loss: 0.0549, Train Acc: 98.58%
  Val Loss: 0.1117, Val Acc: 95.54%
Epoch [5/50]
  Train Loss: 0.0151, Train Acc: 99.75%
  Val Loss: 0.0025, Val Acc: 99.88%
Epoch [10/50]
  Train Loss: 0.0105, Train Acc: 99.85%
  Val Loss: 0.0039, Val Acc: 99.92%
Epoch [15/50]
  Train Loss: 0.0083, Train Acc: 99.89%
  Val Loss: 0.0000, Val Acc: 100.00%
Epoch [20/50]
  Train Loss: 0.0093, Train Acc: 99.90%
  Val Loss: 0.0001, Val Acc: 100.00%

Early stopping at epoch 22
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_sliding_window__cnn1d_wide/prep_sliding_window__cnn1d_wide_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn1d_wide/prep_sliding_window__cnn1d_wide_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn1d_wide/prep_sliding_window__cnn1d_wide_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_sliding_window__cnn1d_wide/prep_sliding_window__cnn1d_wide_classification_report.txt
Saved: saved_models_pytorch/prep_sliding_window__cnn1d_wide.pth

Training: prep_sliding_window__cnn_lstm_base

============================================================
Training prep_sliding_window__cnn_lstm_base
============================================================
Epoch [1/50]
  Train Loss: 0.0619, Train Acc: 98.26%
  Val Loss: 0.0006, Val Acc: 99.98%
Epoch [5/50]
  Train Loss: 0.0102, Train Acc: 99.80%
  Val Loss: 0.0008, Val Acc: 99.98%
Epoch [10/50]
  Train Loss: 0.0068, Train Acc: 99.89%
  Val Loss: 0.0024, Val Acc: 99.96%

Early stopping at epoch 14
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_sliding_window__cnn_lstm_base/prep_sliding_window__cnn_lstm_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn_lstm_base/prep_sliding_window__cnn_lstm_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn_lstm_base/prep_sliding_window__cnn_lstm_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_sliding_window__cnn_lstm_base/prep_sliding_window__cnn_lstm_base_classification_report.txt
Saved: saved_models_pytorch/prep_sliding_window__cnn_lstm_base.pth

Training: prep_sliding_window__cnn_lstm_large

============================================================
Training prep_sliding_window__cnn_lstm_large
============================================================
Epoch [1/50]
  Train Loss: 0.0763, Train Acc: 97.64%
  Val Loss: 0.0023, Val Acc: 99.92%
Epoch [5/50]
  Train Loss: 0.0117, Train Acc: 99.77%
  Val Loss: 0.0016, Val Acc: 99.95%
Epoch [10/50]
  Train Loss: 0.0098, Train Acc: 99.85%
  Val Loss: 0.0005, Val Acc: 99.99%
Epoch [15/50]
  Train Loss: 0.0036, Train Acc: 99.94%
  Val Loss: 0.0267, Val Acc: 99.86%
Epoch [20/50]
  Train Loss: 0.0023, Train Acc: 99.96%
  Val Loss: 0.0002, Val Acc: 100.00%
Epoch [25/50]
  Train Loss: 0.0024, Train Acc: 99.98%
  Val Loss: 0.0000, Val Acc: 100.00%

Early stopping at epoch 28
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_sliding_window__cnn_lstm_large/prep_sliding_window__cnn_lstm_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn_lstm_large/prep_sliding_window__cnn_lstm_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn_lstm_large/prep_sliding_window__cnn_lstm_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_sliding_window__cnn_lstm_large/prep_sliding_window__cnn_lstm_large_classification_report.txt
Saved: saved_models_pytorch/prep_sliding_window__cnn_lstm_large.pth

Training: prep_sliding_window__cnn_transformer_base

============================================================
Training prep_sliding_window__cnn_transformer_base
============================================================
Epoch [1/50]
  Train Loss: 0.0791, Train Acc: 97.84%
  Val Loss: 0.0191, Val Acc: 99.42%
Epoch [5/50]
  Train Loss: 0.0150, Train Acc: 99.67%
  Val Loss: 0.0073, Val Acc: 99.79%
Epoch [10/50]
  Train Loss: 0.0119, Train Acc: 99.75%
  Val Loss: 0.0014, Val Acc: 99.95%
Epoch [15/50]
  Train Loss: 0.0038, Train Acc: 99.91%
  Val Loss: 0.0009, Val Acc: 99.96%
Epoch [20/50]
  Train Loss: 0.0018, Train Acc: 99.96%
  Val Loss: 0.0000, Val Acc: 100.00%

Early stopping at epoch 23
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_sliding_window__cnn_transformer_base/prep_sliding_window__cnn_transformer_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn_transformer_base/prep_sliding_window__cnn_transformer_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn_transformer_base/prep_sliding_window__cnn_transformer_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_sliding_window__cnn_transformer_base/prep_sliding_window__cnn_transformer_base_classification_report.txt
Saved: saved_models_pytorch/prep_sliding_window__cnn_transformer_base.pth

Training: prep_sliding_window__cnn_transformer_large

============================================================
Training prep_sliding_window__cnn_transformer_large
============================================================
Epoch [1/50]
  Train Loss: 1.5947, Train Acc: 23.73%
  Val Loss: 1.6060, Val Acc: 23.23%
Epoch [5/50]
  Train Loss: 1.6057, Train Acc: 23.23%
  Val Loss: 1.6055, Val Acc: 23.23%
Epoch [10/50]
  Train Loss: 1.6057, Train Acc: 23.23%
  Val Loss: 1.6058, Val Acc: 23.23%

Early stopping at epoch 11
Best validation accuracy: 23.23%

Training completed. Best validation accuracy: 23.23%
Saved training curves: saved_models_pytorch/reports/prep_sliding_window__cnn_transformer_large/prep_sliding_window__cnn_transformer_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn_transformer_large/prep_sliding_window__cnn_transformer_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_sliding_window__cnn_transformer_large/prep_sliding_window__cnn_transformer_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_sliding_window__cnn_transformer_large/prep_sliding_window__cnn_transformer_large_classification_report.txt
Saved: saved_models_pytorch/prep_sliding_window__cnn_transformer_large.pth

------------------------------------------------------------
Preprocessing: prep_minmax
--- Loading data from ./AllSmaples-Report ---
Loaded 6540 sequences
Sequence shape: (100, 9)
Number of classes: 5
Class distribution: {0: 1520, 1: 1327, 2: 1284, 3: 1247, 4: 1162}
Normalization: none
Window stride: 100 (non-overlapping)
Drift handling: Disabled

Training: prep_minmax__cnn1d_base

============================================================
Training prep_minmax__cnn1d_base
============================================================
Epoch [1/50]
  Train Loss: 0.6831, Train Acc: 71.38%
  Val Loss: 0.2404, Val Acc: 91.44%
Epoch [5/50]
  Train Loss: 0.1419, Train Acc: 96.36%
  Val Loss: 0.0738, Val Acc: 97.66%
Epoch [10/50]
  Train Loss: 0.1040, Train Acc: 97.58%
  Val Loss: 0.0148, Val Acc: 99.90%
Epoch [15/50]
  Train Loss: 0.0360, Train Acc: 99.18%
  Val Loss: 0.0353, Val Acc: 98.47%
Epoch [20/50]
  Train Loss: 0.0340, Train Acc: 98.85%
  Val Loss: 0.0165, Val Acc: 99.59%

Early stopping at epoch 20
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_minmax__cnn1d_base/prep_minmax__cnn1d_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn1d_base/prep_minmax__cnn1d_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn1d_base/prep_minmax__cnn1d_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_minmax__cnn1d_base/prep_minmax__cnn1d_base_classification_report.txt
Saved: saved_models_pytorch/prep_minmax__cnn1d_base.pth

Training: prep_minmax__cnn1d_deep

============================================================
Training prep_minmax__cnn1d_deep
============================================================
Epoch [1/50]
  Train Loss: 1.1584, Train Acc: 47.76%
  Val Loss: 0.5628, Val Acc: 74.21%
Epoch [5/50]
  Train Loss: 0.2154, Train Acc: 94.29%
  Val Loss: 0.4546, Val Acc: 87.67%
Epoch [10/50]
  Train Loss: 0.2130, Train Acc: 95.01%
  Val Loss: 0.1128, Val Acc: 97.15%
Epoch [15/50]
  Train Loss: 0.1898, Train Acc: 95.18%
  Val Loss: 0.0562, Val Acc: 98.17%
Epoch [20/50]
  Train Loss: 0.1112, Train Acc: 97.22%
  Val Loss: 0.3066, Val Acc: 96.33%
Epoch [25/50]
  Train Loss: 0.1008, Train Acc: 97.17%
  Val Loss: 0.7475, Val Acc: 86.85%

Early stopping at epoch 26
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_minmax__cnn1d_deep/prep_minmax__cnn1d_deep_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn1d_deep/prep_minmax__cnn1d_deep_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn1d_deep/prep_minmax__cnn1d_deep_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_minmax__cnn1d_deep/prep_minmax__cnn1d_deep_classification_report.txt
Saved: saved_models_pytorch/prep_minmax__cnn1d_deep.pth

Training: prep_minmax__cnn1d_wide

============================================================
Training prep_minmax__cnn1d_wide
============================================================
Epoch [1/50]
  Train Loss: 0.5193, Train Acc: 80.78%
  Val Loss: 0.1097, Val Acc: 95.92%
Epoch [5/50]
  Train Loss: 0.0954, Train Acc: 96.81%
  Val Loss: 0.0178, Val Acc: 99.08%
Epoch [10/50]
  Train Loss: 0.0552, Train Acc: 98.34%
  Val Loss: 0.0423, Val Acc: 97.96%
Epoch [15/50]
  Train Loss: 0.0785, Train Acc: 98.11%
  Val Loss: 0.0893, Val Acc: 98.06%
Epoch [20/50]
  Train Loss: 0.0290, Train Acc: 99.34%
  Val Loss: 0.0112, Val Acc: 99.80%
Epoch [25/50]
  Train Loss: 0.0332, Train Acc: 99.03%
  Val Loss: 0.0033, Val Acc: 99.90%

Early stopping at epoch 26
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_minmax__cnn1d_wide/prep_minmax__cnn1d_wide_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn1d_wide/prep_minmax__cnn1d_wide_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn1d_wide/prep_minmax__cnn1d_wide_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_minmax__cnn1d_wide/prep_minmax__cnn1d_wide_classification_report.txt
Saved: saved_models_pytorch/prep_minmax__cnn1d_wide.pth

Training: prep_minmax__cnn_lstm_base

============================================================
Training prep_minmax__cnn_lstm_base
============================================================
Epoch [1/50]
  Train Loss: 0.9756, Train Acc: 54.03%
  Val Loss: 0.5636, Val Acc: 72.38%
Epoch [5/50]
  Train Loss: 0.3132, Train Acc: 89.98%
  Val Loss: 0.1111, Val Acc: 95.72%
Epoch [10/50]
  Train Loss: 0.1369, Train Acc: 96.59%
  Val Loss: 0.0664, Val Acc: 97.96%
Epoch [15/50]
  Train Loss: 0.0511, Train Acc: 98.34%
  Val Loss: 0.0067, Val Acc: 99.90%
Epoch [20/50]
  Train Loss: 0.0659, Train Acc: 98.42%
  Val Loss: 0.0047, Val Acc: 99.69%
Epoch [25/50]
  Train Loss: 0.0227, Train Acc: 99.49%
  Val Loss: 0.0018, Val Acc: 99.90%
Epoch [30/50]
  Train Loss: 0.0152, Train Acc: 99.49%
  Val Loss: 0.0099, Val Acc: 99.80%

Early stopping at epoch 34
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_minmax__cnn_lstm_base/prep_minmax__cnn_lstm_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn_lstm_base/prep_minmax__cnn_lstm_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn_lstm_base/prep_minmax__cnn_lstm_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_minmax__cnn_lstm_base/prep_minmax__cnn_lstm_base_classification_report.txt
Saved: saved_models_pytorch/prep_minmax__cnn_lstm_base.pth

Training: prep_minmax__cnn_lstm_large

============================================================
Training prep_minmax__cnn_lstm_large
============================================================
Epoch [1/50]
  Train Loss: 0.8781, Train Acc: 56.50%
  Val Loss: 0.5432, Val Acc: 62.79%
Epoch [5/50]
  Train Loss: 0.3030, Train Acc: 91.39%
  Val Loss: 0.1655, Val Acc: 93.88%
Epoch [10/50]
  Train Loss: 0.1264, Train Acc: 96.48%
  Val Loss: 0.0715, Val Acc: 96.53%
Epoch [15/50]
  Train Loss: 0.0947, Train Acc: 97.50%
  Val Loss: 0.0603, Val Acc: 98.17%
Epoch [20/50]
  Train Loss: 0.0654, Train Acc: 98.37%
  Val Loss: 0.3303, Val Acc: 90.93%

Early stopping at epoch 22
Best validation accuracy: 99.08%

Training completed. Best validation accuracy: 99.08%
Saved training curves: saved_models_pytorch/reports/prep_minmax__cnn_lstm_large/prep_minmax__cnn_lstm_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn_lstm_large/prep_minmax__cnn_lstm_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn_lstm_large/prep_minmax__cnn_lstm_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_minmax__cnn_lstm_large/prep_minmax__cnn_lstm_large_classification_report.txt
Saved: saved_models_pytorch/prep_minmax__cnn_lstm_large.pth

Training: prep_minmax__cnn_transformer_base

============================================================
Training prep_minmax__cnn_transformer_base
============================================================
Epoch [1/50]
  Train Loss: 0.9443, Train Acc: 58.08%
  Val Loss: 0.4062, Val Acc: 87.36%
Epoch [5/50]
  Train Loss: 0.1554, Train Acc: 95.92%
  Val Loss: 0.1261, Val Acc: 96.53%
Epoch [10/50]
  Train Loss: 0.1080, Train Acc: 97.83%
  Val Loss: 0.0119, Val Acc: 99.69%
Epoch [15/50]
  Train Loss: 0.0976, Train Acc: 97.68%
  Val Loss: 0.0201, Val Acc: 99.39%
Epoch [20/50]
  Train Loss: 0.0640, Train Acc: 98.01%
  Val Loss: 0.0473, Val Acc: 98.27%
Epoch [25/50]
  Train Loss: 0.0294, Train Acc: 99.26%
  Val Loss: 0.0005, Val Acc: 100.00%

Early stopping at epoch 27
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_minmax__cnn_transformer_base/prep_minmax__cnn_transformer_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn_transformer_base/prep_minmax__cnn_transformer_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn_transformer_base/prep_minmax__cnn_transformer_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_minmax__cnn_transformer_base/prep_minmax__cnn_transformer_base_classification_report.txt
Saved: saved_models_pytorch/prep_minmax__cnn_transformer_base.pth

Training: prep_minmax__cnn_transformer_large

============================================================
Training prep_minmax__cnn_transformer_large
============================================================
Epoch [1/50]
  Train Loss: 1.1116, Train Acc: 49.75%
  Val Loss: 1.2856, Val Acc: 42.20%
Epoch [5/50]
  Train Loss: 1.6105, Train Acc: 21.87%
  Val Loss: 1.6065, Val Acc: 23.24%
Epoch [10/50]
  Train Loss: 1.6085, Train Acc: 22.55%
  Val Loss: 1.6061, Val Acc: 23.24%

Early stopping at epoch 13
Best validation accuracy: 43.43%

Training completed. Best validation accuracy: 43.43%
Saved training curves: saved_models_pytorch/reports/prep_minmax__cnn_transformer_large/prep_minmax__cnn_transformer_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn_transformer_large/prep_minmax__cnn_transformer_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_minmax__cnn_transformer_large/prep_minmax__cnn_transformer_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_minmax__cnn_transformer_large/prep_minmax__cnn_transformer_large_classification_report.txt
Saved: saved_models_pytorch/prep_minmax__cnn_transformer_large.pth

------------------------------------------------------------
Preprocessing: prep_robust
--- Loading data from ./AllSmaples-Report ---
Loaded 6540 sequences
Sequence shape: (100, 9)
Number of classes: 5
Class distribution: {0: 1520, 1: 1327, 2: 1284, 3: 1247, 4: 1162}
Normalization: none
Window stride: 100 (non-overlapping)
Drift handling: Disabled

Training: prep_robust__cnn1d_base

============================================================
Training prep_robust__cnn1d_base
============================================================
Epoch [1/50]
  Train Loss: 0.7038, Train Acc: 71.25%
  Val Loss: 0.1244, Val Acc: 97.55%
Epoch [5/50]
  Train Loss: 0.2096, Train Acc: 94.67%
  Val Loss: 0.0240, Val Acc: 99.39%
Epoch [10/50]
  Train Loss: 0.0786, Train Acc: 97.81%
  Val Loss: 0.0070, Val Acc: 99.80%
Epoch [15/50]
  Train Loss: 0.0547, Train Acc: 98.55%
  Val Loss: 0.0240, Val Acc: 99.39%
Epoch [20/50]
  Train Loss: 0.0232, Train Acc: 99.52%
  Val Loss: 0.0281, Val Acc: 99.29%
Epoch [25/50]
  Train Loss: 0.0225, Train Acc: 99.29%
  Val Loss: 0.0114, Val Acc: 99.90%

Early stopping at epoch 27
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_robust__cnn1d_base/prep_robust__cnn1d_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_robust__cnn1d_base/prep_robust__cnn1d_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_robust__cnn1d_base/prep_robust__cnn1d_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_robust__cnn1d_base/prep_robust__cnn1d_base_classification_report.txt
Saved: saved_models_pytorch/prep_robust__cnn1d_base.pth

Training: prep_robust__cnn1d_deep

============================================================
Training prep_robust__cnn1d_deep
============================================================
Epoch [1/50]
  Train Loss: 1.0916, Train Acc: 48.09%
  Val Loss: 0.8159, Val Acc: 63.51%
Epoch [5/50]
  Train Loss: 0.4877, Train Acc: 75.51%
  Val Loss: 0.7881, Val Acc: 66.26%
Epoch [10/50]
  Train Loss: 0.3683, Train Acc: 80.15%
  Val Loss: 0.4738, Val Acc: 75.94%
Epoch [15/50]
  Train Loss: 0.2132, Train Acc: 95.49%
  Val Loss: 0.1061, Val Acc: 97.25%
Epoch [20/50]
  Train Loss: 0.1886, Train Acc: 95.92%
  Val Loss: 0.2125, Val Acc: 92.25%
Epoch [25/50]
  Train Loss: 0.0889, Train Acc: 97.40%
  Val Loss: 0.3116, Val Acc: 93.99%
Epoch [30/50]
  Train Loss: 0.0785, Train Acc: 98.04%
  Val Loss: 0.0183, Val Acc: 99.69%
Epoch [35/50]
  Train Loss: 0.0398, Train Acc: 98.90%
  Val Loss: 0.1278, Val Acc: 97.55%
Epoch [40/50]
  Train Loss: 0.0343, Train Acc: 99.16%
  Val Loss: 0.0287, Val Acc: 99.39%

Early stopping at epoch 44
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_robust__cnn1d_deep/prep_robust__cnn1d_deep_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_robust__cnn1d_deep/prep_robust__cnn1d_deep_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_robust__cnn1d_deep/prep_robust__cnn1d_deep_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_robust__cnn1d_deep/prep_robust__cnn1d_deep_classification_report.txt
Saved: saved_models_pytorch/prep_robust__cnn1d_deep.pth

Training: prep_robust__cnn1d_wide

============================================================
Training prep_robust__cnn1d_wide
============================================================
Epoch [1/50]
  Train Loss: 0.4566, Train Acc: 82.93%
  Val Loss: 0.1078, Val Acc: 97.04%
Epoch [5/50]
  Train Loss: 0.0841, Train Acc: 97.40%
  Val Loss: 0.0096, Val Acc: 99.59%
Epoch [10/50]
  Train Loss: 0.0861, Train Acc: 97.66%
  Val Loss: 0.0204, Val Acc: 99.69%
Epoch [15/50]
  Train Loss: 0.0206, Train Acc: 99.41%
  Val Loss: 0.2458, Val Acc: 91.34%
Epoch [20/50]
  Train Loss: 0.0545, Train Acc: 98.60%
  Val Loss: 0.0325, Val Acc: 99.29%

Early stopping at epoch 22
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_robust__cnn1d_wide/prep_robust__cnn1d_wide_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_robust__cnn1d_wide/prep_robust__cnn1d_wide_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_robust__cnn1d_wide/prep_robust__cnn1d_wide_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_robust__cnn1d_wide/prep_robust__cnn1d_wide_classification_report.txt
Saved: saved_models_pytorch/prep_robust__cnn1d_wide.pth

Training: prep_robust__cnn_lstm_base

============================================================
Training prep_robust__cnn_lstm_base
============================================================
Epoch [1/50]
  Train Loss: 0.9116, Train Acc: 56.88%
  Val Loss: 0.5408, Val Acc: 79.41%
Epoch [5/50]
  Train Loss: 0.2438, Train Acc: 92.43%
  Val Loss: 0.1227, Val Acc: 96.33%
Epoch [10/50]
  Train Loss: 0.1189, Train Acc: 96.92%
  Val Loss: 0.0072, Val Acc: 99.90%
Epoch [15/50]
  Train Loss: 0.0772, Train Acc: 97.91%
  Val Loss: 0.0090, Val Acc: 99.69%
Epoch [20/50]
  Train Loss: 0.0706, Train Acc: 97.86%
  Val Loss: 0.0231, Val Acc: 99.49%
Epoch [25/50]
  Train Loss: 0.0386, Train Acc: 99.06%
  Val Loss: 0.0095, Val Acc: 99.69%

Early stopping at epoch 26
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_robust__cnn_lstm_base/prep_robust__cnn_lstm_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_robust__cnn_lstm_base/prep_robust__cnn_lstm_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_robust__cnn_lstm_base/prep_robust__cnn_lstm_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_robust__cnn_lstm_base/prep_robust__cnn_lstm_base_classification_report.txt
Saved: saved_models_pytorch/prep_robust__cnn_lstm_base.pth

Training: prep_robust__cnn_lstm_large

============================================================
Training prep_robust__cnn_lstm_large
============================================================
Epoch [1/50]
  Train Loss: 0.8263, Train Acc: 59.05%
  Val Loss: 0.5392, Val Acc: 67.58%
Epoch [5/50]
  Train Loss: 0.2084, Train Acc: 94.29%
  Val Loss: 0.0782, Val Acc: 98.47%
Epoch [10/50]
  Train Loss: 0.1361, Train Acc: 96.53%
  Val Loss: 0.0428, Val Acc: 98.98%
Epoch [15/50]
  Train Loss: 0.0338, Train Acc: 98.80%
  Val Loss: 0.0158, Val Acc: 99.39%
Epoch [20/50]
  Train Loss: 0.0413, Train Acc: 99.03%
  Val Loss: 0.0157, Val Acc: 99.49%
Epoch [25/50]
  Train Loss: 0.0350, Train Acc: 99.08%
  Val Loss: 0.0230, Val Acc: 99.69%
Epoch [30/50]
  Train Loss: 0.0159, Train Acc: 99.67%
  Val Loss: 0.0073, Val Acc: 99.90%

Early stopping at epoch 31
Best validation accuracy: 99.90%

Training completed. Best validation accuracy: 99.90%
Saved training curves: saved_models_pytorch/reports/prep_robust__cnn_lstm_large/prep_robust__cnn_lstm_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_robust__cnn_lstm_large/prep_robust__cnn_lstm_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_robust__cnn_lstm_large/prep_robust__cnn_lstm_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_robust__cnn_lstm_large/prep_robust__cnn_lstm_large_classification_report.txt
Saved: saved_models_pytorch/prep_robust__cnn_lstm_large.pth

Training: prep_robust__cnn_transformer_base

============================================================
Training prep_robust__cnn_transformer_base
============================================================
Epoch [1/50]
  Train Loss: 0.7552, Train Acc: 70.49%
  Val Loss: 0.2159, Val Acc: 92.86%
Epoch [5/50]
  Train Loss: 0.1867, Train Acc: 95.31%
  Val Loss: 0.1664, Val Acc: 96.33%
Epoch [10/50]
  Train Loss: 0.0815, Train Acc: 98.11%
  Val Loss: 0.1484, Val Acc: 94.80%
Epoch [15/50]
  Train Loss: 0.0409, Train Acc: 99.18%
  Val Loss: 0.0156, Val Acc: 99.59%
Epoch [20/50]
  Train Loss: 0.0460, Train Acc: 98.88%
  Val Loss: 0.0080, Val Acc: 99.69%
Epoch [25/50]
  Train Loss: 0.0407, Train Acc: 98.93%
  Val Loss: 0.0172, Val Acc: 99.39%
Epoch [30/50]
  Train Loss: 0.0323, Train Acc: 98.93%
  Val Loss: 0.0006, Val Acc: 100.00%

Early stopping at epoch 32
Best validation accuracy: 100.00%

Training completed. Best validation accuracy: 100.00%
Saved training curves: saved_models_pytorch/reports/prep_robust__cnn_transformer_base/prep_robust__cnn_transformer_base_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_robust__cnn_transformer_base/prep_robust__cnn_transformer_base_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_robust__cnn_transformer_base/prep_robust__cnn_transformer_base_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_robust__cnn_transformer_base/prep_robust__cnn_transformer_base_classification_report.txt
Saved: saved_models_pytorch/prep_robust__cnn_transformer_base.pth

Training: prep_robust__cnn_transformer_large

============================================================
Training prep_robust__cnn_transformer_large
============================================================
Epoch [1/50]
  Train Loss: 1.0323, Train Acc: 54.05%
  Val Loss: 1.2220, Val Acc: 53.21%
Epoch [5/50]
  Train Loss: 1.1095, Train Acc: 49.72%
  Val Loss: 1.0348, Val Acc: 56.57%
Epoch [10/50]
  Train Loss: 0.8569, Train Acc: 57.24%
  Val Loss: 0.7895, Val Acc: 53.92%
Epoch [15/50]
  Train Loss: 0.8626, Train Acc: 58.33%
  Val Loss: 0.8396, Val Acc: 58.92%
Epoch [20/50]
  Train Loss: 0.8410, Train Acc: 56.88%
  Val Loss: 1.1674, Val Acc: 45.46%

Early stopping at epoch 24
Best validation accuracy: 60.96%

Training completed. Best validation accuracy: 60.96%
Saved training curves: saved_models_pytorch/reports/prep_robust__cnn_transformer_large/prep_robust__cnn_transformer_large_training_curves.png
Saved validation confusion matrix: saved_models_pytorch/reports/prep_robust__cnn_transformer_large/prep_robust__cnn_transformer_large_validation_confusion_matrix.png
Saved test confusion matrix: saved_models_pytorch/reports/prep_robust__cnn_transformer_large/prep_robust__cnn_transformer_large_test_confusion_matrix.png
Saved classification report: saved_models_pytorch/reports/prep_robust__cnn_transformer_large/prep_robust__cnn_transformer_large_classification_report.txt
Saved: saved_models_pytorch/prep_robust__cnn_transformer_large.pth

============================================================
ALL CONFIGURATIONS SAVED SUCCESSFULLY
============================================================
Saved 42 trained configurations
Saved training results to 'training_results_all_configs.pkl'
