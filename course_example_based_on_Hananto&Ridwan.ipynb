{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b04899cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit Mapping for files without D1-D5:\n",
      "==================================================\n",
      "AppleBanana: AppleBanana.csv\n",
      "AppleBananaMandarin: AppleBananaMandarin.csv\n",
      "AppleBananaTomato: AppleBananaTomato.csv\n",
      "AppleMandarin: AppleMandarin.csv\n",
      "AppleTomato: AppleTomato.csv\n",
      "BananaMandarin: BananaMandarin.csv\n",
      "Mandarin: Mandarin.csv\n",
      "TomatoBanana: TomatoBanana.csv\n",
      "TomatoMandarin: TomatoMandarin.csv\n",
      "\n",
      "Total files mapped: 9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Directory path\n",
    "report_dir = \"./AllSmaples-Report/\"\n",
    "\n",
    "# Get all CSV files that do NOT contain D1, D2, D3, D4, or D5\n",
    "all_csv_files = glob.glob(os.path.join(report_dir, \"*.csv\"))\n",
    "fruit_mapping = {}\n",
    "\n",
    "for file_path in all_csv_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    # Check if filename does NOT contain D1, D2, D3, D4, or D5\n",
    "    if not any(f\"D{i}\" in filename for i in range(1, 6)):\n",
    "        # Remove .csv extension and use as key, filename as value\n",
    "        fruit_name = filename.replace(\".csv\", \"\")\n",
    "        fruit_mapping[fruit_name] = filename\n",
    "\n",
    "# Display the mapping\n",
    "print(\"Fruit Mapping for files without D1-D5:\")\n",
    "print(\"=\" * 50)\n",
    "for fruit_name, filename in sorted(fruit_mapping.items()):\n",
    "    print(f\"{fruit_name}: {filename}\")\n",
    "\n",
    "print(f\"\\nTotal files mapped: {len(fruit_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35d2861b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Mandarin.csv...\n",
      "  - Loaded 14963 samples\n",
      "Loading AppleBananaTomato.csv...\n",
      "  - Loaded 17651 samples\n",
      "Loading AppleMandarin.csv...\n",
      "  - Loaded 20911 samples\n",
      "Loading BananaMandarin.csv...\n",
      "  - Loaded 21499 samples\n",
      "Loading TomatoMandarin.csv...\n",
      "  - Loaded 21541 samples\n",
      "Loading TomatoBanana.csv...\n",
      "  - Loaded 23158 samples\n",
      "Loading AppleBanana.csv...\n",
      "  - Loaded 21501 samples\n",
      "Loading AppleBananaMandarin.csv...\n",
      "  - Loaded 18952 samples\n",
      "Loading AppleTomato.csv...\n",
      "  - Loaded 21695 samples\n",
      "\n",
      "==================================================\n",
      "Full DataFrame created:\n",
      "  - Total samples: 181871\n",
      "  - Total columns: 11\n",
      "  - Columns: ['Ticks', 'MQ2', 'MQ3', 'MQ4', 'MQ5', 'MQ6', 'MQ7', 'MQ8', 'MQ9', 'MQ135', 'label']\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "AppleBanana            21501\n",
      "AppleBananaMandarin    18952\n",
      "AppleBananaTomato      17651\n",
      "AppleMandarin          20911\n",
      "AppleTomato            21695\n",
      "BananaMandarin         21499\n",
      "Mandarin               14963\n",
      "TomatoBanana           23158\n",
      "TomatoMandarin         21541\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load all mapped CSV files and add label column\n",
    "dataframes = []\n",
    "\n",
    "for fruit_name, filename in fruit_mapping.items():\n",
    "    file_path = os.path.join(report_dir, filename)\n",
    "    print(f\"Loading {filename}...\")\n",
    "    \n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Add label column with the mapped fruit name\n",
    "    df['label'] = fruit_name\n",
    "    \n",
    "    # Append to list\n",
    "    dataframes.append(df)\n",
    "    \n",
    "    print(f\"  - Loaded {len(df)} samples\")\n",
    "\n",
    "# Combine all dataframes into one full dataframe\n",
    "full_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"Full DataFrame created:\")\n",
    "print(f\"  - Total samples: {len(full_dataframe)}\")\n",
    "print(f\"  - Total columns: {len(full_dataframe.columns)}\")\n",
    "print(f\"  - Columns: {list(full_dataframe.columns)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(full_dataframe['label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e559ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of Full DataFrame:\n",
      "==================================================\n",
      "           Ticks  MQ2  MQ3  MQ4  MQ5  MQ6  MQ7  MQ8  MQ9  MQ135     label\n",
      "0  1650986958099   42  180   64   27   63   22   93   46    786  Mandarin\n",
      "1  1650986958113   44  167   65   25   59   30   82   54    764  Mandarin\n",
      "2  1650986958121   41  166   63   18   60   31   82   52    769  Mandarin\n",
      "3  1650986958129   45  170   66   25   59   25   80   54    766  Mandarin\n",
      "4  1650986958136   45  166   64   21   61   28   85   58    769  Mandarin\n",
      "5  1650986958144   40  165   63   19   59   30   85   53    766  Mandarin\n",
      "6  1650986958152   41  169   65   30   59   26   85   54    767  Mandarin\n",
      "7  1650986958161   41  170   65   25   61   32   84   54    767  Mandarin\n",
      "8  1650986958170   47  175   56   34   71   24   78   66    762  Mandarin\n",
      "9  1650986958180   38  187   55   38   47   43   92   47    777  Mandarin\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181871 entries, 0 to 181870\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Ticks   181871 non-null  int64 \n",
      " 1   MQ2     181871 non-null  int64 \n",
      " 2   MQ3     181871 non-null  int64 \n",
      " 3   MQ4     181871 non-null  int64 \n",
      " 4   MQ5     181871 non-null  int64 \n",
      " 5   MQ6     181871 non-null  int64 \n",
      " 6   MQ7     181871 non-null  int64 \n",
      " 7   MQ8     181871 non-null  int64 \n",
      " 8   MQ9     181871 non-null  int64 \n",
      " 9   MQ135   181871 non-null  int64 \n",
      " 10  label   181871 non-null  object\n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 15.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display preview of the full dataframe\n",
    "print(\"Preview of Full DataFrame:\")\n",
    "print(\"=\" * 50)\n",
    "print(full_dataframe.head(10))\n",
    "print(f\"\\nDataFrame Info:\")\n",
    "print(full_dataframe.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d5fcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame rows have been randomly shuffled:\n",
      "==================================================\n",
      "Total samples: 181871\n",
      "\n",
      "First 10 rows after shuffling:\n",
      "           Ticks  MQ2  MQ3  MQ4  MQ5  MQ6  MQ7  MQ8  MQ9  MQ135  \\\n",
      "0  1650984907823   75  239   79   82  107   58  196   81   1262   \n",
      "1  1650986236703   55  349   75   83   95   62  222   83   1166   \n",
      "2  1650985588586   61  200   67   58   96   53  156   71   1102   \n",
      "3  1650985406803   63  122   80   40   96   54  117   74    942   \n",
      "4  1650984824843   60  241   75   78  106   53  186   75   1243   \n",
      "5  1650987052423   48  290   71   69  105   66  215   73   1265   \n",
      "6  1650985280734   61  116   71   37   88   49  117   74    903   \n",
      "7  1650986148978   48  368   73   90   98   63  249   76   1109   \n",
      "8  1650984318675   82  308   87  114  127   60  281   94   1480   \n",
      "9  1650984917190   68  225   83   74  106   55  179   75   1254   \n",
      "\n",
      "               label  \n",
      "0       TomatoBanana  \n",
      "1      AppleMandarin  \n",
      "2  AppleBananaTomato  \n",
      "3        AppleTomato  \n",
      "4       TomatoBanana  \n",
      "5           Mandarin  \n",
      "6        AppleTomato  \n",
      "7      AppleMandarin  \n",
      "8        AppleBanana  \n",
      "9       TomatoBanana  \n",
      "\n",
      "Label distribution (unchanged - only order changed):\n",
      "label\n",
      "AppleBanana            21501\n",
      "AppleBananaMandarin    18952\n",
      "AppleBananaTomato      17651\n",
      "AppleMandarin          20911\n",
      "AppleTomato            21695\n",
      "BananaMandarin         21499\n",
      "Mandarin               14963\n",
      "TomatoBanana           23158\n",
      "TomatoMandarin         21541\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Randomly shuffle all rows in the full dataframe\n",
    "# Using sample(frac=1.0) to randomly reorder all rows without changing the samples themselves\n",
    "# reset_index(drop=True) to reset the index after shuffling\n",
    "full_dataframe = full_dataframe.sample(frac=1.0, random_state=None).reset_index(drop=True)\n",
    "\n",
    "print(\"DataFrame rows have been randomly shuffled:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total samples: {len(full_dataframe)}\")\n",
    "print(f\"\\nFirst 10 rows after shuffling:\")\n",
    "print(full_dataframe.head(10))\n",
    "print(f\"\\nLabel distribution (unchanged - only order changed):\")\n",
    "print(full_dataframe['label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56654537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the updated dataframe:\n",
      "           Ticks  MQ2  MQ3  MQ4  MQ5  MQ6  MQ7  MQ8  MQ9  MQ135  label\n",
      "0  1650986958099   42  180   64   27   63   22   93   46    786      6\n",
      "1  1650986958113   44  167   65   25   59   30   82   54    764      6\n",
      "2  1650986958121   41  166   63   18   60   31   82   52    769      6\n",
      "3  1650986958129   45  170   66   25   59   25   80   54    766      6\n",
      "4  1650986958136   45  166   64   21   61   28   85   58    769      6\n"
     ]
    }
   ],
   "source": [
    "full_dataframe.head()\n",
    "# Create a mapping from fruit names to multiclass integer labels\n",
    "label_map = {name: idx for idx, name in enumerate(sorted(full_dataframe['label'].unique()))}\n",
    "full_dataframe['label'] = full_dataframe['label'].map(label_map)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "print(\"\\nFirst few rows of the updated dataframe:\")\n",
    "print(full_dataframe.head())\n",
    "# Create a mapping from fruit names to multiclass integer labels\n",
    "label_map = {name: idx for idx, name in enumerate(sorted(full_dataframe['label'].unique()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ea08d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split:\n",
      "============================================================\n",
      "Full dataset: 181871 samples\n",
      "Train+Validation: 145496 samples (80.0%)\n",
      "Test set (held out): 36375 samples (20.0%)\n",
      "\n",
      "Number of features: 9\n",
      "Number of classes: 9\n",
      "\n",
      "Class distribution in train+validation:\n",
      "  Class 0: 17201 samples (11.82%)\n",
      "  Class 1: 15161 samples (10.42%)\n",
      "  Class 2: 14121 samples (9.71%)\n",
      "  Class 3: 16729 samples (11.50%)\n",
      "  Class 4: 17356 samples (11.93%)\n",
      "  Class 5: 17199 samples (11.82%)\n",
      "  Class 6: 11970 samples (8.23%)\n",
      "  Class 7: 18526 samples (12.73%)\n",
      "  Class 8: 17233 samples (11.84%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE PIPELINE: Feature Preprocessing, Multiple Algorithms, CV, Test Set\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create reverse label mapping for class names\n",
    "# Recover fruit names from fruit_mapping (the original names)\n",
    "try:\n",
    "    # Try to get original fruit names from fruit_mapping\n",
    "    fruit_names_sorted = sorted(fruit_mapping.keys())\n",
    "    # Create mapping: integer label -> fruit name\n",
    "    # We need to match the order used when labels were encoded\n",
    "    unique_labels = sorted(full_dataframe['label'].unique())\n",
    "    if len(unique_labels) == len(fruit_names_sorted):\n",
    "        label_to_name = {int(unique_labels[i]): fruit_names_sorted[i] for i in range(len(unique_labels))}\n",
    "    else:\n",
    "        # Fallback: create from label_map if it exists\n",
    "        if 'label_map' in locals():\n",
    "            label_to_name = {v: k for k, v in label_map.items()}\n",
    "        else:\n",
    "            label_to_name = {i: f'Class_{i}' for i in unique_labels}\n",
    "except:\n",
    "    # Fallback: use generic class names\n",
    "    unique_labels = sorted(full_dataframe['label'].unique())\n",
    "    label_to_name = {i: f'Class_{i}' for i in unique_labels}\n",
    "\n",
    "# Prepare features and labels\n",
    "# Exclude 'Ticks' if it's a timestamp and not useful for classification\n",
    "feature_columns = ['MQ2', 'MQ3', 'MQ4', 'MQ5', 'MQ6', 'MQ7', 'MQ8', 'MQ9', 'MQ135']\n",
    "X = full_dataframe[feature_columns].values\n",
    "y = full_dataframe['label'].values\n",
    "\n",
    "# Split into train+validation and test sets (80-20 split)\n",
    "# Stratified split to maintain class distribution\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Data Split:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Full dataset: {len(X)} samples\")\n",
    "print(f\"Train+Validation: {len(X_temp)} samples ({len(X_temp)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set (held out): {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nNumber of features: {X.shape[1]}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"\\nClass distribution in train+validation:\")\n",
    "unique, counts = np.unique(y_temp, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  Class {u}: {c} samples ({c/len(y_temp)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae65d782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models defined with preprocessing pipelines:\n",
      "============================================================\n",
      "  ✓ ANN (MLP)\n",
      "  ✓ KNN\n",
      "  ✓ SVM\n",
      "  ✓ Logistic Regression\n",
      "  ✓ XGBoost\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Define Models with Preprocessing Pipelines\n",
    "# ============================================================================\n",
    "\n",
    "# StandardScaler for feature normalization (important for SVM, ANN, KNN)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define all models with preprocessing\n",
    "models = {\n",
    "    'ANN (MLP)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', MLPClassifier(\n",
    "            hidden_layer_sizes=(100, 50),\n",
    "            max_iter=500,\n",
    "            random_state=42,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1\n",
    "        ))\n",
    "    ]),\n",
    "    'KNN': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42))\n",
    "    ]),\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', XGBClassifier(\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss',\n",
    "            use_label_encoder=False\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"Models defined with preprocessing pipelines:\")\n",
    "print(\"=\" * 60)\n",
    "for name in models.keys():\n",
    "    print(f\"  ✓ {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67350e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400.01s - Error patching args (debugger not attached to subprocess).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_monkey.py\", line 541, in patch_args\n",
      "    new_args.append(_get_python_c_args(host, port, code, unquoted_args, SetupHolder.setup))\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_monkey.py\", line 193, in _get_python_c_args\n",
      "    if \"__future__\" in code:\n",
      "       ^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: a bytes-like object is required, not 'str'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5-Fold Stratified Cross-Validation...\n",
      "============================================================\n",
      "\n",
      "ANN (MLP):\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.9979 (+/- 0.0010)\n",
      "  F1-Score: 0.9979 (+/- 0.0010)\n",
      "  Fold accuracies: ['0.9973', '0.9980', '0.9982', '0.9975', '0.9987']\n",
      "\n",
      "KNN:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/.venv/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.9950 (+/- 0.0005)\n",
      "  F1-Score: 0.9948 (+/- 0.0005)\n",
      "  Fold accuracies: ['0.9947', '0.9950', '0.9952', '0.9948', '0.9953']\n",
      "\n",
      "SVM:\n",
      "----------------------------------------\n",
      "  Accuracy: 0.9968 (+/- 0.0006)\n",
      "  F1-Score: 0.9967 (+/- 0.0006)\n",
      "  Fold accuracies: ['0.9965', '0.9967', '0.9970', '0.9965', '0.9974']\n",
      "\n",
      "Logistic Regression:\n",
      "----------------------------------------\n",
      "  Accuracy: 0.9538 (+/- 0.0031)\n",
      "  F1-Score: 0.9500 (+/- 0.0033)\n",
      "  Fold accuracies: ['0.9546', '0.9519', '0.9535', '0.9526', '0.9563']\n",
      "\n",
      "XGBoost:\n",
      "----------------------------------------\n",
      "  Accuracy: 0.9982 (+/- 0.0002)\n",
      "  F1-Score: 0.9981 (+/- 0.0002)\n",
      "  Fold accuracies: ['0.9984', '0.9981', '0.9981', '0.9980', '0.9982']\n",
      "\n",
      "============================================================\n",
      "Cross-Validation Summary:\n",
      "============================================================\n",
      "Model                     CV Accuracy          CV F1-Score         \n",
      "------------------------------------------------------------\n",
      "XGBoost                   0.9982 ± 0.0001   0.9981 ± 0.0001\n",
      "ANN (MLP)                 0.9979 ± 0.0005   0.9979 ± 0.0005\n",
      "SVM                       0.9968 ± 0.0003   0.9967 ± 0.0003\n",
      "KNN                       0.9950 ± 0.0002   0.9948 ± 0.0002\n",
      "Logistic Regression       0.9538 ± 0.0016   0.9500 ± 0.0017\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# K-Fold Cross-Validation (5-Fold Stratified)\n",
    "# ============================================================================\n",
    "\n",
    "# Setup K-Fold Cross-Validation (5 folds, stratified)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store CV results\n",
    "cv_results = {}\n",
    "\n",
    "print(\"Performing 5-Fold Stratified Cross-Validation...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Perform cross-validation with accuracy scoring\n",
    "    cv_scores = cross_val_score(model, X_temp, y_temp, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    # Also get F1 scores (macro-averaged)\n",
    "    cv_f1_scores = cross_val_score(model, X_temp, y_temp, cv=kfold, scoring='f1_macro', n_jobs=-1)\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'accuracy_mean': cv_scores.mean(),\n",
    "        'accuracy_std': cv_scores.std(),\n",
    "        'accuracy_scores': cv_scores,\n",
    "        'f1_mean': cv_f1_scores.mean(),\n",
    "        'f1_std': cv_f1_scores.std(),\n",
    "        'f1_scores': cv_f1_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(f\"  F1-Score: {cv_f1_scores.mean():.4f} (+/- {cv_f1_scores.std() * 2:.4f})\")\n",
    "    print(f\"  Fold accuracies: {[f'{s:.4f}' for s in cv_scores]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Cross-Validation Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<25} {'CV Accuracy':<20} {'CV F1-Score':<20}\")\n",
    "print(\"-\" * 60)\n",
    "for name in sorted(cv_results.keys(), key=lambda x: cv_results[x]['accuracy_mean'], reverse=True):\n",
    "    acc = cv_results[name]['accuracy_mean']\n",
    "    f1 = cv_results[name]['f1_mean']\n",
    "    print(f\"{name:<25} {acc:.4f} ± {cv_results[name]['accuracy_std']:.4f}   {f1:.4f} ± {cv_results[name]['f1_std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd4b404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final models on full train+validation set...\n",
      "Evaluating on held-out test set...\n",
      "============================================================\n",
      "\n",
      "ANN (MLP):\n",
      "----------------------------------------\n",
      "  Test Accuracy: 0.9978\n",
      "  Test F1-Score: 0.9978\n",
      "\n",
      "KNN:\n",
      "----------------------------------------\n",
      "  Test Accuracy: 0.9955\n",
      "  Test F1-Score: 0.9953\n",
      "\n",
      "SVM:\n",
      "----------------------------------------\n",
      "  Test Accuracy: 0.9967\n",
      "  Test F1-Score: 0.9966\n",
      "\n",
      "Logistic Regression:\n",
      "----------------------------------------\n",
      "  Test Accuracy: 0.9536\n",
      "  Test F1-Score: 0.9497\n",
      "\n",
      "XGBoost:\n",
      "----------------------------------------\n",
      "  Test Accuracy: 0.9985\n",
      "  Test F1-Score: 0.9985\n",
      "\n",
      "============================================================\n",
      "Final Test Set Results (Held-Out):\n",
      "============================================================\n",
      "Model                     Test Accuracy        Test F1-Score       \n",
      "------------------------------------------------------------\n",
      "XGBoost                   0.9985              0.9985\n",
      "ANN (MLP)                 0.9978              0.9978\n",
      "SVM                       0.9967              0.9966\n",
      "KNN                       0.9955              0.9953\n",
      "Logistic Regression       0.9536              0.9497\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Train Final Models and Evaluate on Held-Out Test Set\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Training final models on full train+validation set...\")\n",
    "print(\"Evaluating on held-out test set...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_results = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train on full train+validation set\n",
    "    model.fit(X_temp, y_temp)\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    test_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'y_pred': y_pred,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "    \n",
    "    print(f\"  Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Test F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Final Test Set Results (Held-Out):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<25} {'Test Accuracy':<20} {'Test F1-Score':<20}\")\n",
    "print(\"-\" * 60)\n",
    "for name in sorted(test_results.keys(), key=lambda x: test_results[x]['accuracy'], reverse=True):\n",
    "    acc = test_results[name]['accuracy']\n",
    "    f1 = test_results[name]['f1_score']\n",
    "    print(f\"{name:<25} {acc:.4f}              {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2b631c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Classification Reports on Test Set:\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ANN (MLP)\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        AppleBanana     1.0000    1.0000    1.0000      4300\n",
      "AppleBananaMandarin     0.9963    0.9918    0.9941      3791\n",
      "  AppleBananaTomato     0.9966    0.9960    0.9963      3530\n",
      "      AppleMandarin     0.9990    0.9998    0.9994      4182\n",
      "        AppleTomato     1.0000    1.0000    1.0000      4339\n",
      "     BananaMandarin     0.9995    0.9993    0.9994      4300\n",
      "           Mandarin     0.9987    0.9983    0.9985      2993\n",
      "       TomatoBanana     0.9965    0.9970    0.9968      4632\n",
      "     TomatoMandarin     0.9938    0.9974    0.9956      4308\n",
      "\n",
      "           accuracy                         0.9978     36375\n",
      "          macro avg     0.9978    0.9977    0.9978     36375\n",
      "       weighted avg     0.9978    0.9978    0.9978     36375\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4300    0    0    0    0    0    0    0    0]\n",
      " [   0 3760    0    1    0    2    1    1   26]\n",
      " [   0    0 3516    0    0    0    0   14    0]\n",
      " [   0    1    0 4181    0    0    0    0    0]\n",
      " [   0    0    0    0 4339    0    0    0    0]\n",
      " [   0    0    0    3    0 4297    0    0    0]\n",
      " [   0    3    0    0    0    0 2988    1    1]\n",
      " [   0    0   12    0    0    0    2 4618    0]\n",
      " [   0   10    0    0    0    0    1    0 4297]]\n",
      "\n",
      "\n",
      "============================================================\n",
      "KNN\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        AppleBanana     0.9998    1.0000    0.9999      4300\n",
      "AppleBananaMandarin     0.9832    0.9908    0.9870      3791\n",
      "  AppleBananaTomato     0.9923    0.9915    0.9919      3530\n",
      "      AppleMandarin     0.9998    0.9998    0.9998      4182\n",
      "        AppleTomato     0.9993    0.9998    0.9995      4339\n",
      "     BananaMandarin     1.0000    0.9984    0.9992      4300\n",
      "           Mandarin     0.9970    0.9920    0.9945      2993\n",
      "       TomatoBanana     0.9942    0.9937    0.9940      4632\n",
      "     TomatoMandarin     0.9923    0.9912    0.9918      4308\n",
      "\n",
      "           accuracy                         0.9955     36375\n",
      "          macro avg     0.9953    0.9952    0.9953     36375\n",
      "       weighted avg     0.9955    0.9955    0.9955     36375\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4300    0    0    0    0    0    0    0    0]\n",
      " [   0 3756    0    0    0    0    6    0   29]\n",
      " [   0    0 3500    0    3    0    0   27    0]\n",
      " [   0    0    0 4181    0    0    0    0    1]\n",
      " [   0    0    1    0 4338    0    0    0    0]\n",
      " [   0    4    0    0    0 4293    0    0    3]\n",
      " [   0   24    0    0    0    0 2969    0    0]\n",
      " [   0    0   26    0    0    0    3 4603    0]\n",
      " [   1   36    0    1    0    0    0    0 4270]]\n",
      "\n",
      "\n",
      "============================================================\n",
      "SVM\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        AppleBanana     1.0000    1.0000    1.0000      4300\n",
      "AppleBananaMandarin     0.9900    0.9900    0.9900      3791\n",
      "  AppleBananaTomato     0.9955    0.9946    0.9950      3530\n",
      "      AppleMandarin     0.9986    0.9998    0.9992      4182\n",
      "        AppleTomato     1.0000    1.0000    1.0000      4339\n",
      "     BananaMandarin     0.9998    0.9984    0.9991      4300\n",
      "           Mandarin     0.9983    0.9957    0.9970      2993\n",
      "       TomatoBanana     0.9959    0.9961    0.9960      4632\n",
      "     TomatoMandarin     0.9919    0.9944    0.9932      4308\n",
      "\n",
      "           accuracy                         0.9967     36375\n",
      "          macro avg     0.9967    0.9965    0.9966     36375\n",
      "       weighted avg     0.9967    0.9967    0.9967     36375\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4300    0    0    0    0    0    0    0    0]\n",
      " [   0 3753    0    0    0    1    3    0   34]\n",
      " [   0    0 3511    0    0    0    0   19    0]\n",
      " [   0    1    0 4181    0    0    0    0    0]\n",
      " [   0    0    0    0 4339    0    0    0    0]\n",
      " [   0    1    0    6    0 4293    0    0    0]\n",
      " [   0   12    0    0    0    0 2980    0    1]\n",
      " [   0    0   16    0    0    0    2 4614    0]\n",
      " [   0   24    0    0    0    0    0    0 4284]]\n",
      "\n",
      "\n",
      "============================================================\n",
      "LOGISTIC REGRESSION\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        AppleBanana     0.9991    1.0000    0.9995      4300\n",
      "AppleBananaMandarin     0.8432    0.8267    0.8348      3791\n",
      "  AppleBananaTomato     0.9864    0.9867    0.9865      3530\n",
      "      AppleMandarin     0.9933    0.9983    0.9958      4182\n",
      "        AppleTomato     0.9991    0.9998    0.9994      4339\n",
      "     BananaMandarin     0.9914    0.9863    0.9888      4300\n",
      "           Mandarin     0.8623    0.8854    0.8737      2993\n",
      "       TomatoBanana     0.9890    0.9909    0.9900      4632\n",
      "     TomatoMandarin     0.8810    0.8765    0.8788      4308\n",
      "\n",
      "           accuracy                         0.9536     36375\n",
      "          macro avg     0.9494    0.9501    0.9497     36375\n",
      "       weighted avg     0.9535    0.9536    0.9535     36375\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4300    0    0    0    0    0    0    0    0]\n",
      " [   0 3134    2    6    1   14  351    0  283]\n",
      " [   0    0 3483    0    3    0    1   42    1]\n",
      " [   0    1    0 4175    0    0    3    0    3]\n",
      " [   0    0    1    0 4338    0    0    0    0]\n",
      " [   0   35    0    8    0 4241    1    0   15]\n",
      " [   1  131    1    0    0    2 2650    3  205]\n",
      " [   0    0   38    0    0    0    1 4590    3]\n",
      " [   3  416    6   14    0   21   66    6 3776]]\n",
      "\n",
      "\n",
      "============================================================\n",
      "XGBOOST\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        AppleBanana     0.9995    1.0000    0.9998      4300\n",
      "AppleBananaMandarin     0.9953    0.9968    0.9960      3791\n",
      "  AppleBananaTomato     0.9983    0.9966    0.9974      3530\n",
      "      AppleMandarin     0.9998    0.9998    0.9998      4182\n",
      "        AppleTomato     1.0000    1.0000    1.0000      4339\n",
      "     BananaMandarin     0.9995    0.9988    0.9992      4300\n",
      "           Mandarin     0.9993    0.9987    0.9990      2993\n",
      "       TomatoBanana     0.9974    0.9985    0.9980      4632\n",
      "     TomatoMandarin     0.9972    0.9968    0.9970      4308\n",
      "\n",
      "           accuracy                         0.9985     36375\n",
      "          macro avg     0.9985    0.9984    0.9985     36375\n",
      "       weighted avg     0.9985    0.9985    0.9985     36375\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4300    0    0    0    0    0    0    0    0]\n",
      " [   0 3779    0    0    0    2    0    0   10]\n",
      " [   0    1 3518    0    0    0    0   11    0]\n",
      " [   0    0    0 4181    0    0    1    0    0]\n",
      " [   0    0    0    0 4339    0    0    0    0]\n",
      " [   0    2    0    1    0 4295    0    0    2]\n",
      " [   1    2    0    0    0    0 2989    1    0]\n",
      " [   0    0    6    0    0    0    1 4625    0]\n",
      " [   1   13    0    0    0    0    0    0 4294]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Detailed Classification Reports for Each Model\n",
    "# ============================================================================\n",
    "\n",
    "# Get class names for better readability\n",
    "class_names = [label_to_name[i] for i in sorted(label_to_name.keys())]\n",
    "\n",
    "print(\"Detailed Classification Reports on Test Set:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name in models.keys():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    y_test_vals = test_results[name]['y_test']\n",
    "    y_pred_vals = test_results[name]['y_pred']\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_vals, y_pred_vals, target_names=class_names, digits=4))\n",
    "    \n",
    "    print(f\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test_vals, y_pred_vals)\n",
    "    print(cm)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f279356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Performance Summary:\n",
      "================================================================================\n",
      "              Model     CV Accuracy Test Accuracy     CV F1-Score Test F1-Score\n",
      "            XGBoost 0.9982 ± 0.0001        0.9985 0.9981 ± 0.0001        0.9985\n",
      "          ANN (MLP) 0.9979 ± 0.0005        0.9978 0.9979 ± 0.0005        0.9978\n",
      "                SVM 0.9968 ± 0.0003        0.9967 0.9967 ± 0.0003        0.9966\n",
      "                KNN 0.9950 ± 0.0002        0.9955 0.9948 ± 0.0002        0.9953\n",
      "Logistic Regression 0.9538 ± 0.0016        0.9536 0.9500 ± 0.0017        0.9497\n",
      "\n",
      "================================================================================\n",
      "Best Model (by Test Accuracy): XGBoost\n",
      "Best Test Accuracy: 0.9985\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Summary Comparison: CV vs Test Performance\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "for name in models.keys():\n",
    "    summary_data.append({\n",
    "        'Model': name,\n",
    "        'CV Accuracy': f\"{cv_results[name]['accuracy_mean']:.4f} ± {cv_results[name]['accuracy_std']:.4f}\",\n",
    "        'Test Accuracy': f\"{test_results[name]['accuracy']:.4f}\",\n",
    "        'CV F1-Score': f\"{cv_results[name]['f1_mean']:.4f} ± {cv_results[name]['f1_std']:.4f}\",\n",
    "        'Test F1-Score': f\"{test_results[name]['f1_score']:.4f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('Test Accuracy', ascending=False, key=lambda x: x.str.split().str[0].astype(float))\n",
    "\n",
    "print(\"Complete Performance Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Best Model (by Test Accuracy):\", summary_df.iloc[0]['Model'])\n",
    "print(\"Best Test Accuracy:\", summary_df.iloc[0]['Test Accuracy'])\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f564c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models for production...\n",
      "============================================================\n",
      "  ✓ Saved: saved_models/ann_mlp.joblib\n",
      "  ✓ Saved: saved_models/knn.joblib\n",
      "  ✓ Saved: saved_models/svm.joblib\n",
      "  ✓ Saved: saved_models/logistic_regression.joblib\n",
      "  ✓ Saved: saved_models/xgboost.joblib\n",
      "  ✓ Saved metadata: saved_models/metadata.joblib\n",
      "\n",
      "============================================================\n",
      "All models and metadata saved successfully!\n",
      "Models directory: /home/abel/Project/2026/EduSaf-Feb2026/DL_Course/MQ-ML/saved_models\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Save Models and Metadata for Production Use\n",
    "# ============================================================================\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = 'saved_models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save each trained model\n",
    "print(\"Saving models for production...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    # Clean model name for filename (remove special characters)\n",
    "    model_filename = name.replace(' ', '_').replace('(', '').replace(')', '').lower()\n",
    "    model_path = os.path.join(models_dir, f'{model_filename}.joblib')\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"  ✓ Saved: {model_path}\")\n",
    "\n",
    "# Save metadata (label mapping, feature columns, etc.)\n",
    "metadata = {\n",
    "    'label_to_name': label_to_name,\n",
    "    'name_to_label': {v: k for k, v in label_to_name.items()},\n",
    "    'feature_columns': feature_columns,\n",
    "    'num_classes': len(np.unique(y)),\n",
    "    'test_results': {k: {'accuracy': v['accuracy'], 'f1_score': v['f1_score']} \n",
    "                     for k, v in test_results.items()},\n",
    "    'cv_results': {k: {'accuracy_mean': v['accuracy_mean'], 'accuracy_std': v['accuracy_std'],\n",
    "                       'f1_mean': v['f1_mean'], 'f1_std': v['f1_std']}\n",
    "                   for k, v in cv_results.items()},\n",
    "    'saved_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'best_model': summary_df.iloc[0]['Model']\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(models_dir, 'metadata.joblib')\n",
    "joblib.dump(metadata, metadata_path)\n",
    "print(f\"  ✓ Saved metadata: {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All models and metadata saved successfully!\")\n",
    "print(f\"Models directory: {os.path.abspath(models_dir)}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
